{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29c7f67",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Trading Environment\n",
    "This notebook sets up a custom trading environment for reinforcement learning using OpenAI Gym.\n",
    "We will:\n",
    "- Load preprocessed trading data.\n",
    "- Define the trading environment (state, actions, rewards).\n",
    "- Implement a Gym-compatible RL environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321993bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "# Load preprocessed data\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Convert datadate to datetime format\n",
    "train_df['datadate'] = pd.to_datetime(train_df['datadate'])\n",
    "test_df['datadate'] = pd.to_datetime(test_df['datadate'])\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"Custom Trading Environment for RL\"\"\"\n",
    "    def __init__(self, data):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        self.cash = 10000  # Initial cash balance\n",
    "        self.holdings = 0  # Number of shares held\n",
    "        self.action_space = spaces.Discrete(3)  # Buy, Hold, Sell\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(data.columns) - 2,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.cash = 10000\n",
    "        self.holdings = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        return self.data.iloc[self.current_step, 2:].values\n",
    "\n",
    "    def step(self, action):\n",
    "        price = self.data.iloc[self.current_step]['adjcp']\n",
    "\n",
    "        if action == 0:  # Buy\n",
    "            self.holdings += self.cash / price\n",
    "            self.cash = 0\n",
    "        elif action == 1:  # Sell\n",
    "            self.cash += self.holdings * price\n",
    "            self.holdings = 0\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data) - 1\n",
    "        reward = self.cash + (self.holdings * price) - 10000  # Net worth difference\n",
    "        return self._next_observation(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(f'Step: {self.current_step}, Cash: {self.cash}, Holdings: {self.holdings}')\n",
    "\n",
    "# Initialize environment\n",
    "env = TradingEnv(train_df)\n",
    "state = env.reset()\n",
    "print(\"Sample state:\", state)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}