{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c99581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# shares normalization factor\n",
    "# 100 shares per trade\n",
    "HMAX_NORMALIZE = 100\n",
    "# initial amount of money we have in our account\n",
    "INITIAL_ACCOUNT_BALANCE=1000000\n",
    "# total number of stocks in our portfolio\n",
    "STOCK_DIM = 30\n",
    "# transaction fee: 1/1000 reasonable percentage\n",
    "TRANSACTION_FEE_PERCENT = 0.001\n",
    "REWARD_SCALING = 1e-4\n",
    "\n",
    "\n",
    "class StockEnvTrain(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df,day = 0):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.df = df\n",
    "\n",
    "        # action_space normalization and shape is STOCK_DIM\n",
    "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
    "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
    "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.terminal = False             \n",
    "        # initalize state\n",
    "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
    "                      self.data.adjcp.values.tolist() + \\\n",
    "                      [0]*STOCK_DIM + \\\n",
    "                      self.data.macd.values.tolist() + \\\n",
    "                      self.data.rsi.values.tolist() + \\\n",
    "                      self.data.cci.values.tolist() + \\\n",
    "                      self.data.adx.values.tolist()\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        self.cost = 0\n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
    "        self.rewards_memory = []\n",
    "        self.trades = 0\n",
    "        #self.reset()\n",
    "        self._seed()\n",
    "\n",
    "\n",
    "    def _sell_stock(self, index, action):\n",
    "        # perform sell action based on the sign of the action\n",
    "        if self.state[index+STOCK_DIM+1] > 0:\n",
    "            #update balance\n",
    "            self.state[0] += \\\n",
    "            self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
    "             (1- TRANSACTION_FEE_PERCENT)\n",
    "\n",
    "            self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
    "            self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
    "             TRANSACTION_FEE_PERCENT\n",
    "            self.trades+=1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    def _buy_stock(self, index, action):\n",
    "        # perform buy action based on the sign of the action\n",
    "        available_amount = self.state[0] // self.state[index+1]\n",
    "        # print('available_amount:{}'.format(available_amount))\n",
    "\n",
    "        #update balance\n",
    "        self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
    "                          (1+ TRANSACTION_FEE_PERCENT)\n",
    "\n",
    "        self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
    "\n",
    "        self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
    "                          TRANSACTION_FEE_PERCENT\n",
    "        self.trades+=1\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # print(self.day)\n",
    "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
    "        # print(actions)\n",
    "\n",
    "        if self.terminal:\n",
    "            plt.plot(self.asset_memory,'r')\n",
    "            plt.savefig('./working/account_value_train.png') # get rid of leading '\\'\n",
    "            plt.close()\n",
    "            end_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            \n",
    "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
    "            df_total_value = pd.DataFrame(self.asset_memory)\n",
    "            df_total_value.to_csv('./working/account_value_train.csv')\n",
    "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- INITIAL_ACCOUNT_BALANCE ))\n",
    "            #print(\"total_cost: \", self.cost)\n",
    "            #print(\"total_trades: \", self.trades)\n",
    "            df_total_value.columns = ['account_value']\n",
    "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
    "            sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\n",
    "                  df_total_value['daily_return'].std()\n",
    "            #print(\"Sharpe: \",sharpe)\n",
    "            #print(\"=================================\")\n",
    "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
    "            #df_rewards.to_csv('/kaggle./working/account_rewards_train.csv')\n",
    "            \n",
    "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
    "            #with open('obs.pkl', 'wb') as f:  \n",
    "            #    pickle.dump(self.state, f)\n",
    "            \n",
    "            return self.state, self.reward, self.terminal,{}\n",
    "\n",
    "        else:\n",
    "            # print(np.array(self.state[1:29]))\n",
    "\n",
    "            actions = actions * HMAX_NORMALIZE\n",
    "            #actions = (actions.astype(int))\n",
    "            \n",
    "            begin_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
    "            \n",
    "            argsort_actions = np.argsort(actions)\n",
    "            \n",
    "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
    "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
    "\n",
    "            for index in sell_index:\n",
    "                # print('take sell action'.format(actions[index]))\n",
    "                self._sell_stock(index, actions[index])\n",
    "\n",
    "            for index in buy_index:\n",
    "                # print('take buy action: {}'.format(actions[index]))\n",
    "                self._buy_stock(index, actions[index])\n",
    "\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day,:]         \n",
    "            #load next state\n",
    "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
    "            self.state =  [self.state[0]] + \\\n",
    "                    self.data.adjcp.values.tolist() + \\\n",
    "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n",
    "                    self.data.macd.values.tolist() + \\\n",
    "                    self.data.rsi.values.tolist() + \\\n",
    "                    self.data.cci.values.tolist() + \\\n",
    "                    self.data.adx.values.tolist()\n",
    "            \n",
    "            end_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
    "            \n",
    "            self.reward = end_total_asset - begin_total_asset            \n",
    "            # print(\"step_reward:{}\".format(self.reward))\n",
    "            self.rewards_memory.append(self.reward)\n",
    "            \n",
    "            self.reward = self.reward*REWARD_SCALING\n",
    "\n",
    "\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False \n",
    "        self.rewards_memory = []\n",
    "        #initiate state\n",
    "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
    "                      self.data.adjcp.values.tolist() + \\\n",
    "                      [0]*STOCK_DIM + \\\n",
    "                      self.data.macd.values.tolist() + \\\n",
    "                      self.data.rsi.values.tolist() + \\\n",
    "                      self.data.cci.values.tolist() + \\\n",
    "                      self.data.adx.values.tolist() \n",
    "        # iteration += 1 \n",
    "        return self.state\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ff05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# shares normalization factor\n",
    "# 100 shares per trade\n",
    "HMAX_NORMALIZE = 100\n",
    "# initial amount of money we have in our account\n",
    "INITIAL_ACCOUNT_BALANCE=1000000\n",
    "# total number of stocks in our portfolio\n",
    "STOCK_DIM = 30\n",
    "# transaction fee: 1/1000 reasonable percentage\n",
    "TRANSACTION_FEE_PERCENT = 0.001\n",
    "\n",
    "# turbulence index: 90-150 reasonable threshold\n",
    "#TURBULENCE_THRESHOLD = 140\n",
    "REWARD_SCALING = 1e-4\n",
    "\n",
    "class StockEnvTrade(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df,day = 0,turbulence_threshold=140\n",
    "                 ,initial=True, previous_state=[], model_name='', iteration=''):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.df = df\n",
    "        self.initial = initial\n",
    "        self.previous_state = previous_state\n",
    "        # action_space normalization and shape is STOCK_DIM\n",
    "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
    "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
    "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.terminal = False     \n",
    "        self.turbulence_threshold = turbulence_threshold\n",
    "        # initalize state\n",
    "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
    "                      self.data.adjcp.values.tolist() + \\\n",
    "                      [0]*STOCK_DIM + \\\n",
    "                      self.data.macd.values.tolist() + \\\n",
    "                      self.data.rsi.values.tolist() + \\\n",
    "                      self.data.cci.values.tolist() + \\\n",
    "                      self.data.adx.values.tolist()\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
    "        self.rewards_memory = []\n",
    "        #self.reset()\n",
    "        self._seed()\n",
    "        self.model_name=model_name        \n",
    "        self.iteration=iteration\n",
    "\n",
    "\n",
    "    def _sell_stock(self, index, action):\n",
    "        # perform sell action based on the sign of the action\n",
    "        if self.turbulence<self.turbulence_threshold:\n",
    "            if self.state[index+STOCK_DIM+1] > 0:\n",
    "                #update balance\n",
    "                self.state[0] += \\\n",
    "                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
    "                 (1- TRANSACTION_FEE_PERCENT)\n",
    "                \n",
    "                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
    "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
    "                 TRANSACTION_FEE_PERCENT\n",
    "                self.trades+=1\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            # if turbulence goes over threshold, just clear out all positions \n",
    "            if self.state[index+STOCK_DIM+1] > 0:\n",
    "                #update balance\n",
    "                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
    "                              (1- TRANSACTION_FEE_PERCENT)\n",
    "                self.state[index+STOCK_DIM+1] =0\n",
    "                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
    "                              TRANSACTION_FEE_PERCENT\n",
    "                self.trades+=1\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    def _buy_stock(self, index, action):\n",
    "        # perform buy action based on the sign of the action\n",
    "        if self.turbulence< self.turbulence_threshold:\n",
    "            available_amount = self.state[0] // self.state[index+1]\n",
    "            # print('available_amount:{}'.format(available_amount))\n",
    "            \n",
    "            #update balance\n",
    "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
    "                              (1+ TRANSACTION_FEE_PERCENT)\n",
    "\n",
    "            self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
    "            \n",
    "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
    "                              TRANSACTION_FEE_PERCENT\n",
    "            self.trades+=1\n",
    "        else:\n",
    "            # if turbulence goes over threshold, just stop buying\n",
    "            pass\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # print(self.day)\n",
    "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
    "        # print(actions)\n",
    "\n",
    "        if self.terminal:\n",
    "            plt.plot(self.asset_memory,'r')\n",
    "            plt.savefig('./working/account_value_trade_{}_{}.png'.format(self.model_name, self.iteration))\n",
    "            plt.close()\n",
    "            df_total_value = pd.DataFrame(self.asset_memory)\n",
    "            df_total_value.to_csv('./working/account_value_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n",
    "            end_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n",
    "\n",
    "            print(\"end_total_asset:{}\".format(end_total_asset))\n",
    "            print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))- self.asset_memory[0] ))\n",
    "            print(\"total_cost: \", self.cost)\n",
    "            print(\"total trades: \", self.trades)\n",
    "\n",
    "            df_total_value.columns = ['account_value']\n",
    "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
    "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n",
    "                  df_total_value['daily_return'].std()\n",
    "            print(\"Sharpe: \",sharpe)\n",
    "            \n",
    "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
    "            df_rewards.to_csv('./working/account_rewards_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n",
    "            \n",
    "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
    "            #with open('obs.pkl', 'wb') as f:  \n",
    "            #    pickle.dump(self.state, f)\n",
    "            \n",
    "            return self.state, self.reward, self.terminal,{}\n",
    "\n",
    "        else:\n",
    "            # print(np.array(self.state[1:29]))\n",
    "\n",
    "            actions = actions * HMAX_NORMALIZE\n",
    "            #actions = (actions.astype(int))\n",
    "            if self.turbulence>=self.turbulence_threshold:\n",
    "                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\n",
    "                \n",
    "            begin_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
    "            \n",
    "            argsort_actions = np.argsort(actions)\n",
    "            \n",
    "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
    "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
    "\n",
    "            for index in sell_index:\n",
    "                # print('take sell action'.format(actions[index]))\n",
    "                self._sell_stock(index, actions[index])\n",
    "\n",
    "            for index in buy_index:\n",
    "                # print('take buy action: {}'.format(actions[index]))\n",
    "                self._buy_stock(index, actions[index])\n",
    "\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day,:]         \n",
    "            self.turbulence = self.data['turbulence'].values[0]\n",
    "            #print(self.turbulence)\n",
    "            #load next state\n",
    "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
    "            self.state =  [self.state[0]] + \\\n",
    "                    self.data.adjcp.values.tolist() + \\\n",
    "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n",
    "                    self.data.macd.values.tolist() + \\\n",
    "                    self.data.rsi.values.tolist() + \\\n",
    "                    self.data.cci.values.tolist() + \\\n",
    "                    self.data.adx.values.tolist()\n",
    "            \n",
    "            end_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
    "            \n",
    "            self.reward = end_total_asset - begin_total_asset            \n",
    "            # print(\"step_reward:{}\".format(self.reward))\n",
    "            self.rewards_memory.append(self.reward)\n",
    "            \n",
    "            self.reward = self.reward*REWARD_SCALING\n",
    "\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):  \n",
    "        if self.initial:\n",
    "            self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
    "            self.day = 0\n",
    "            self.data = self.df.loc[self.day,:]\n",
    "            self.turbulence = 0\n",
    "            self.cost = 0\n",
    "            self.trades = 0\n",
    "            self.terminal = False \n",
    "            #self.iteration=self.iteration\n",
    "            self.rewards_memory = []\n",
    "            #initiate state\n",
    "            self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
    "                          self.data.adjcp.values.tolist() + \\\n",
    "                          [0]*STOCK_DIM + \\\n",
    "                          self.data.macd.values.tolist() + \\\n",
    "                          self.data.rsi.values.tolist()  + \\\n",
    "                          self.data.cci.values.tolist()  + \\\n",
    "                          self.data.adx.values.tolist() \n",
    "        else:\n",
    "            previous_total_asset = self.previous_state[0]+ \\\n",
    "            sum(np.array(self.previous_state[1:(STOCK_DIM+1)])*np.array(self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            self.asset_memory = [previous_total_asset]\n",
    "            #self.asset_memory = [self.previous_state[0]]\n",
    "            self.day = 0\n",
    "            self.data = self.df.loc[self.day,:]\n",
    "            self.turbulence = 0\n",
    "            self.cost = 0\n",
    "            self.trades = 0\n",
    "            self.terminal = False \n",
    "            #self.iteration=iteration\n",
    "            self.rewards_memory = []\n",
    "            #initiate state\n",
    "            #self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]\n",
    "            #[0]*STOCK_DIM + \\\n",
    "\n",
    "            self.state = [ self.previous_state[0]] + \\\n",
    "                          self.data.adjcp.values.tolist() + \\\n",
    "                          self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]+ \\\n",
    "                          self.data.macd.values.tolist() + \\\n",
    "                          self.data.rsi.values.tolist()  + \\\n",
    "                          self.data.cci.values.tolist()  + \\\n",
    "                          self.data.adx.values.tolist() \n",
    "            \n",
    "        return self.state\n",
    "    \n",
    "    def render(self, mode='human',close=False):\n",
    "        return self.state\n",
    "    \n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eae39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# shares normalization factor\n",
    "# 100 shares per trade\n",
    "HMAX_NORMALIZE = 100\n",
    "# initial amount of money we have in our account\n",
    "INITIAL_ACCOUNT_BALANCE=1000000\n",
    "# total number of stocks in our portfolio\n",
    "STOCK_DIM = 30\n",
    "# transaction fee: 1/1000 reasonable percentage\n",
    "TRANSACTION_FEE_PERCENT = 0.001\n",
    "\n",
    "# turbulence index: 90-150 reasonable threshold\n",
    "#TURBULENCE_THRESHOLD = 140\n",
    "REWARD_SCALING = 1e-4\n",
    "\n",
    "class StockEnvValidation(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, day = 0, turbulence_threshold=140, iteration=''):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.df = df\n",
    "        # action_space normalization and shape is STOCK_DIM\n",
    "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
    "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
    "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.terminal = False     \n",
    "        self.turbulence_threshold = turbulence_threshold\n",
    "        # initalize state\n",
    "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
    "                      self.data.adjcp.values.tolist() + \\\n",
    "                      [0]*STOCK_DIM + \\\n",
    "                      self.data.macd.values.tolist() + \\\n",
    "                      self.data.rsi.values.tolist() + \\\n",
    "                      self.data.cci.values.tolist() + \\\n",
    "                      self.data.adx.values.tolist()\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
    "        self.rewards_memory = []\n",
    "        #self.reset()\n",
    "        self._seed()\n",
    "        \n",
    "        self.iteration=iteration\n",
    "\n",
    "\n",
    "    def _sell_stock(self, index, action):\n",
    "        # perform sell action based on the sign of the action\n",
    "        if self.turbulence<self.turbulence_threshold:\n",
    "            if self.state[index+STOCK_DIM+1] > 0:\n",
    "                #update balance\n",
    "                self.state[0] += \\\n",
    "                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
    "                 (1- TRANSACTION_FEE_PERCENT)\n",
    "                \n",
    "                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
    "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
    "                 TRANSACTION_FEE_PERCENT\n",
    "                self.trades+=1\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            # if turbulence goes over threshold, just clear out all positions \n",
    "            if self.state[index+STOCK_DIM+1] > 0:\n",
    "                #update balance\n",
    "                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
    "                              (1- TRANSACTION_FEE_PERCENT)\n",
    "                self.state[index+STOCK_DIM+1] =0\n",
    "                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
    "                              TRANSACTION_FEE_PERCENT\n",
    "                self.trades+=1\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    def _buy_stock(self, index, action):\n",
    "        # perform buy action based on the sign of the action\n",
    "        if self.turbulence< self.turbulence_threshold:\n",
    "            available_amount = self.state[0] // self.state[index+1]\n",
    "            # print('available_amount:{}'.format(available_amount))\n",
    "            \n",
    "            #update balance\n",
    "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
    "                              (1+ TRANSACTION_FEE_PERCENT)\n",
    "\n",
    "            self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
    "            \n",
    "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
    "                              TRANSACTION_FEE_PERCENT\n",
    "            self.trades+=1\n",
    "        else:\n",
    "            # if turbulence goes over threshold, just stop buying\n",
    "            pass\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # print(self.day)\n",
    "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
    "        # print(actions)\n",
    "\n",
    "        if self.terminal:\n",
    "            plt.plot(self.asset_memory,'r')\n",
    "            plt.savefig('./working/account_value_validation_{}.png'.format(self.iteration))\n",
    "            plt.close()\n",
    "            df_total_value = pd.DataFrame(self.asset_memory)\n",
    "            df_total_value.to_csv('./working/account_value_validation_{}.csv'.format(self.iteration))\n",
    "            end_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            #print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n",
    "\n",
    "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
    "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- self.asset_memory[0] ))\n",
    "            #print(\"total_cost: \", self.cost)\n",
    "            #print(\"total trades: \", self.trades)\n",
    "\n",
    "            df_total_value.columns = ['account_value']\n",
    "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
    "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n",
    "                  df_total_value['daily_return'].std()\n",
    "            #print(\"Sharpe: \",sharpe)\n",
    "            \n",
    "            #df_rewards = pd.DataFrame(self.rewards_memory)\n",
    "            #df_rewards.to_csv('/kaggle./working/account_rewards_trade_{}.csv'.format(self.iteration))\n",
    "            \n",
    "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
    "            #with open('obs.pkl', 'wb') as f:  \n",
    "            #    pickle.dump(self.state, f)\n",
    "            \n",
    "            return self.state, self.reward, self.terminal,{}\n",
    "\n",
    "        else:\n",
    "            # print(np.array(self.state[1:29]))\n",
    "\n",
    "            actions = actions * HMAX_NORMALIZE\n",
    "            #actions = (actions.astype(int))\n",
    "            if self.turbulence>=self.turbulence_threshold:\n",
    "                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\n",
    "            begin_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
    "            \n",
    "            argsort_actions = np.argsort(actions)\n",
    "            \n",
    "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
    "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
    "\n",
    "            for index in sell_index:\n",
    "                # print('take sell action'.format(actions[index]))\n",
    "                self._sell_stock(index, actions[index])\n",
    "\n",
    "            for index in buy_index:\n",
    "                # print('take buy action: {}'.format(actions[index]))\n",
    "                self._buy_stock(index, actions[index])\n",
    "\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day,:]         \n",
    "            self.turbulence = self.data['turbulence'].values[0]\n",
    "            #print(self.turbulence)\n",
    "            #load next state\n",
    "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
    "            self.state =  [self.state[0]] + \\\n",
    "                    self.data.adjcp.values.tolist() + \\\n",
    "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n",
    "                    self.data.macd.values.tolist() + \\\n",
    "                    self.data.rsi.values.tolist() + \\\n",
    "                    self.data.cci.values.tolist() + \\\n",
    "                    self.data.adx.values.tolist()\n",
    "            \n",
    "            end_total_asset = self.state[0]+ \\\n",
    "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
    "            \n",
    "            self.reward = end_total_asset - begin_total_asset            \n",
    "            # print(\"step_reward:{}\".format(self.reward))\n",
    "            self.rewards_memory.append(self.reward)\n",
    "            \n",
    "            self.reward = self.reward*REWARD_SCALING\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):  \n",
    "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.turbulence = 0\n",
    "        self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False \n",
    "        #self.iteration=self.iteration\n",
    "        self.rewards_memory = []\n",
    "        #initiate state\n",
    "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
    "                      self.data.adjcp.values.tolist() + \\\n",
    "                      [0]*STOCK_DIM + \\\n",
    "                      self.data.macd.values.tolist() + \\\n",
    "                      self.data.rsi.values.tolist()  + \\\n",
    "                      self.data.cci.values.tolist()  + \\\n",
    "                      self.data.adx.values.tolist() \n",
    "            \n",
    "        return self.state\n",
    "    \n",
    "    def render(self, mode='human',close=False):\n",
    "        return self.state\n",
    "    \n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smooth-clothing",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-03T04:57:54.198152Z",
     "iopub.status.busy": "2021-04-03T04:57:54.197005Z",
     "iopub.status.idle": "2021-04-03T05:00:42.175245Z",
     "shell.execute_reply": "2021-04-03T05:00:42.173533Z"
    },
    "papermill": {
     "duration": 167.993805,
     "end_time": "2021-04-03T05:00:42.175556",
     "exception": false,
     "start_time": "2021-04-03T04:57:54.181751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willr\\miniconda3\\envs\\sb_env\\lib\\site-packages\\stable_baselines\\__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#from env.EnvMultipleStock_train import StockEnvTrain\n",
    "#from env.EnvMultipleStock_validation import StockEnvValidation\n",
    "#from env.EnvMultipleStock_trade import StockEnvTrade\n",
    "\n",
    "#!pip uninstall -y tensorflow-probability\n",
    "#!pip uninstall -y tensorflow-cloud\n",
    "#!pip uninstall -y pytorch-lightning\n",
    "#!pip uninstall -y tensorflow\n",
    "#!pip uninstall -y gast\n",
    "\n",
    "#!pip install -qq 'tensorflow==1.15.0'\n",
    "import tensorflow as tf\n",
    "\n",
    "#!apt-get update > /dev/null\n",
    "#!apt-get install -qq -y cmake libopenmpi-dev python3-dev zlib1g-dev\n",
    "#!pip install -qq \"stable-baselines[mpi]==2.9.0\"\n",
    "\n",
    "from stable_baselines import GAIL, SAC\n",
    "from stable_baselines import ACER\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines import DDPG\n",
    "from stable_baselines import TD3\n",
    "from stable_baselines import DQN\n",
    "\n",
    "from stable_baselines.ddpg.policies import DDPGPolicy\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy\n",
    "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
    "from stable_baselines.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-calcium",
   "metadata": {
    "papermill": {
     "duration": 0.035776,
     "end_time": "2021-04-03T05:00:42.246099",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.210323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"dataset\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Dataset\n",
    "        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "registered-specialist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:42.319007Z",
     "iopub.status.busy": "2021-04-03T05:00:42.318274Z",
     "iopub.status.idle": "2021-04-03T05:00:42.766545Z",
     "shell.execute_reply": "2021-04-03T05:00:42.765961Z"
    },
    "papermill": {
     "duration": 0.486202,
     "end_time": "2021-04-03T05:00:42.766718",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.280516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datadate</th>\n",
       "      <th>tic</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi</th>\n",
       "      <th>cci</th>\n",
       "      <th>adx</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20090102</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>12.964286</td>\n",
       "      <td>12.268571</td>\n",
       "      <td>13.005714</td>\n",
       "      <td>12.165714</td>\n",
       "      <td>26641980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20090102</td>\n",
       "      <td>AXP</td>\n",
       "      <td>19.330000</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>10955620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20090102</td>\n",
       "      <td>BA</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>42.800000</td>\n",
       "      <td>45.560000</td>\n",
       "      <td>42.780000</td>\n",
       "      <td>7010171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20090102</td>\n",
       "      <td>CAT</td>\n",
       "      <td>46.910000</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.710000</td>\n",
       "      <td>7116726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20090102</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.960000</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>40977480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  datadate   tic      adjcp       open       high        low  \\\n",
       "0           0  20090102  AAPL  12.964286  12.268571  13.005714  12.165714   \n",
       "1           1  20090102   AXP  19.330000  18.570000  19.520000  18.400000   \n",
       "2           2  20090102    BA  45.250000  42.800000  45.560000  42.780000   \n",
       "3           3  20090102   CAT  46.910000  44.910000  46.980000  44.710000   \n",
       "4           4  20090102  CSCO  16.960000  16.410000  17.000000  16.250000   \n",
       "\n",
       "       volume  macd    rsi        cci    adx  turbulence  \n",
       "0  26641980.0   0.0  100.0  66.666667  100.0         0.0  \n",
       "1  10955620.0   0.0  100.0  66.666667  100.0         0.0  \n",
       "2   7010171.0   0.0  100.0  66.666667  100.0         0.0  \n",
       "3   7116726.0   0.0    0.0  66.666667  100.0         0.0  \n",
       "4  40977480.0   0.0  100.0  66.666667  100.0         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = '/kaggle/input/trading/trading.csv'\n",
    "path = 'trading.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "understanding-fields",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:42.841646Z",
     "iopub.status.busy": "2021-04-03T05:00:42.841006Z",
     "iopub.status.idle": "2021-04-03T05:00:42.845211Z",
     "shell.execute_reply": "2021-04-03T05:00:42.844583Z"
    },
    "papermill": {
     "duration": 0.043923,
     "end_time": "2021-04-03T05:00:42.845383",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.801460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63\n",
    "validation_window = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cheap-madison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:42.927058Z",
     "iopub.status.busy": "2021-04-03T05:00:42.925790Z",
     "iopub.status.idle": "2021-04-03T05:00:42.938471Z",
     "shell.execute_reply": "2021-04-03T05:00:42.937753Z"
    },
    "papermill": {
     "duration": 0.055925,
     "end_time": "2021-04-03T05:00:42.938636",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.882711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n"
     ]
    }
   ],
   "source": [
    "unique_trade_date = df[(df.datadate > 20151001)&(df.datadate <= 20200707)].datadate.unique()\n",
    "print(unique_trade_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-lease",
   "metadata": {
    "papermill": {
     "duration": 0.036451,
     "end_time": "2021-04-03T05:00:43.010626",
     "exception": false,
     "start_time": "2021-04-03T05:00:42.974175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"stable\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Stable Baseline\n",
    "        <a class=\"anchor-link\" href=\"#stable\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "senior-dispatch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.101017Z",
     "iopub.status.busy": "2021-04-03T05:00:43.100132Z",
     "iopub.status.idle": "2021-04-03T05:00:43.103435Z",
     "shell.execute_reply": "2021-04-03T05:00:43.102911Z"
    },
    "papermill": {
     "duration": 0.056248,
     "end_time": "2021-04-03T05:00:43.103598",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.047350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_A2C(env_train, model_name, timesteps=25000):\n",
    "    start = time.time()\n",
    "    model = A2C('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (A2C): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_ACER(env_train, model_name, timesteps=25000):\n",
    "    start = time.time()\n",
    "    model = ACER('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (A2C): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_DDPG(env_train, model_name, timesteps=10000):\n",
    "    # add the noise objects for DDPG\n",
    "    n_actions = env_train.action_space.shape[-1]\n",
    "    param_noise = None\n",
    "    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
    "\n",
    "    start = time.time()\n",
    "    model = DDPG('MlpPolicy', env_train, param_noise=param_noise, action_noise=action_noise)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (DDPG): ', (end-start)/60,' minutes')\n",
    "    return model\n",
    "\n",
    "def train_PPO(env_train, model_name, timesteps=50000):\n",
    "    start = time.time()\n",
    "    model = PPO2('MlpPolicy', env_train, ent_coef = 0.005, nminibatches = 8)\n",
    "    \n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (PPO): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_GAIL(env_train, model_name, timesteps=1000):\n",
    "    start = time.time()\n",
    "    # generate expert trajectories\n",
    "    model = SAC('MLpPolicy', env_train, verbose=1)\n",
    "    GAIL.generate_expert_traj(model, 'expert_model_gail', n_timesteps=100, n_episodes=10)\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = GAIL.ExpertDataset(expert_path='expert_model_gail.npz', traj_limitation=10, verbose=1)\n",
    "    model = GAIL('MLpPolicy', env_train, dataset, verbose=1)\n",
    "\n",
    "    model.learn(total_timesteps=1000)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (PPO): ', (end - start) / 60, ' minutes')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b2338",
   "metadata": {},
   "source": [
    "##### Our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4ff1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DQN(env_train, model_name, timesteps=25000):\n",
    "    start = time.time()\n",
    "    model = DQN('MlpPolicy', env_train, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (DQN): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_TD3(env_train, model_name, timesteps=25000):\n",
    "    n_actions = env_train.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "    \n",
    "    start = time.time()\n",
    "    model = TD3('MlpPolicy', env_train, action_noise=action_noise, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (TD3): ', (end - start) / 60, ' minutes')\n",
    "    return model\n",
    "\n",
    "def train_SAC(env_train, model_name, timesteps=25000):\n",
    "    n_actions = env_train.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "    start = time.time()\n",
    "    model = SAC('MlpPolicy', env_train, action_noise=action_noise, verbose=0)\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    end = time.time()\n",
    "\n",
    "    model.save(f\"./working/{model_name}\")\n",
    "    print(' - Training time (SAC): ', (end - start) / 60, ' minutes')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-camera",
   "metadata": {
    "papermill": {
     "duration": 0.035164,
     "end_time": "2021-04-03T05:00:43.174458",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.139294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"additional\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Additional Functions\n",
    "        <a class=\"anchor-link\" href=\"#additional\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "complex-berkeley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.254427Z",
     "iopub.status.busy": "2021-04-03T05:00:43.253753Z",
     "iopub.status.idle": "2021-04-03T05:00:43.257932Z",
     "shell.execute_reply": "2021-04-03T05:00:43.257250Z"
    },
    "papermill": {
     "duration": 0.048232,
     "end_time": "2021-04-03T05:00:43.258157",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.209925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_split(df,start,end):\n",
    "    data = df[(df.datadate >= start) & (df.datadate < end)]\n",
    "    data=data.sort_values(['datadate','tic'],ignore_index=True)\n",
    "    data.index = data.datadate.factorize()[0]\n",
    "    return data\n",
    "\n",
    "def get_validation_sharpe(iteration):\n",
    "    df_total_value = pd.read_csv('./working/account_value_validation_{}.csv'.format(iteration), index_col=0)\n",
    "    df_total_value.columns = ['account_value_train']\n",
    "    df_total_value['daily_return'] = df_total_value.pct_change(1)\n",
    "    sharpe = (4 ** 0.5) * df_total_value['daily_return'].mean() / \\\n",
    "             df_total_value['daily_return'].std()\n",
    "    return sharpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-sunrise",
   "metadata": {
    "papermill": {
     "duration": 0.034922,
     "end_time": "2021-04-03T05:00:43.328501",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.293579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"predvalid\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Predict-Validate\n",
    "        <a class=\"anchor-link\" href=\"#predvalid\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stock-robert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.411283Z",
     "iopub.status.busy": "2021-04-03T05:00:43.410568Z",
     "iopub.status.idle": "2021-04-03T05:00:43.414371Z",
     "shell.execute_reply": "2021-04-03T05:00:43.413801Z"
    },
    "papermill": {
     "duration": 0.05106,
     "end_time": "2021-04-03T05:00:43.414516",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.363456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DRL_prediction(df,\n",
    "                   model,\n",
    "                   name,\n",
    "                   last_state,\n",
    "                   iter_num,\n",
    "                   unique_trade_date,\n",
    "                   rebalance_window,\n",
    "                   turbulence_threshold,\n",
    "                   initial):\n",
    "\n",
    "    trade_data = data_split(df, start=unique_trade_date[iter_num - rebalance_window], end=unique_trade_date[iter_num])\n",
    "    env_trade = DummyVecEnv([lambda: StockEnvTrade(trade_data,\n",
    "                                                   turbulence_threshold=turbulence_threshold,\n",
    "                                                   initial=initial,\n",
    "                                                   previous_state=last_state,\n",
    "                                                   model_name=name,\n",
    "                                                   iteration=iter_num)])\n",
    "    obs_trade = env_trade.reset()\n",
    "\n",
    "    for i in range(len(trade_data.index.unique())):\n",
    "        action, _states = model.predict(obs_trade)\n",
    "        obs_trade, rewards, dones, info = env_trade.step(action)\n",
    "        if i == (len(trade_data.index.unique()) - 2):\n",
    "            last_state = env_trade.render()\n",
    "\n",
    "    df_last_state = pd.DataFrame({'last_state': last_state})\n",
    "    df_last_state.to_csv('./working/last_state_{}_{}.csv'.format(name, i), index=False)\n",
    "    return last_state\n",
    "\n",
    "def DRL_validation(model, test_data, test_env, test_obs) -> None:\n",
    "    for i in range(len(test_data.index.unique())):\n",
    "        action, _states = model.predict(test_obs)\n",
    "        test_obs, rewards, dones, info = test_env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-anthropology",
   "metadata": {
    "papermill": {
     "duration": 0.036259,
     "end_time": "2021-04-03T05:00:43.486375",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.450116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"ensemble\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>Ensemble\n",
    "        <a class=\"anchor-link\" href=\"#ensemble\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wrapped-pathology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-03T05:00:43.582758Z",
     "iopub.status.busy": "2021-04-03T05:00:43.581780Z",
     "iopub.status.idle": "2021-04-03T05:00:43.585359Z",
     "shell.execute_reply": "2021-04-03T05:00:43.584799Z"
    },
    "papermill": {
     "duration": 0.063935,
     "end_time": "2021-04-03T05:00:43.585499",
     "exception": false,
     "start_time": "2021-04-03T05:00:43.521564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_ensemble_strategy(df, unique_trade_date, rebalance_window, validation_window):\n",
    "    last_state_ensemble = []\n",
    "    ppo_sharpe_list = []\n",
    "    ddpg_sharpe_list = []\n",
    "    a2c_sharpe_list = []\n",
    "\n",
    "    model_use = []\n",
    "\n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            # inital state\n",
    "            initial = True\n",
    "        else:\n",
    "            # previous state\n",
    "            initial = False\n",
    "\n",
    "        # Tuning trubulence index based on historical data\n",
    "        # Turbulence lookback window is one quarter\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window*30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "            # then we assume that the current market is volatile,\n",
    "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        ## validation env\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \",\n",
    "              unique_trade_date[i - rebalance_window - validation_window])\n",
    "        print(\" - A2C Training\")\n",
    "        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i), timesteps=30000)\n",
    "        print(\" - A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_a2c = get_validation_sharpe(i)\n",
    "        print(\" - A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "\n",
    "        print(\" - PPO Training\")\n",
    "        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=100000)\n",
    "        print(\" - PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_ppo = get_validation_sharpe(i)\n",
    "        print(\" - PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "\n",
    "        print(\" - DDPG Training\")\n",
    "        model_ddpg = train_DDPG(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=10000)\n",
    "        print(\" - DDPG Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        \n",
    "        DRL_validation(model=model_ddpg, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_ddpg = get_validation_sharpe(i)\n",
    "\n",
    "        ppo_sharpe_list.append(sharpe_ppo)\n",
    "        a2c_sharpe_list.append(sharpe_a2c)\n",
    "        ddpg_sharpe_list.append(sharpe_ddpg)\n",
    "\n",
    "        # Model Selection based on sharpe ratio\n",
    "        if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
    "            model_ensemble = model_ppo\n",
    "            model_use.append(('PPO', unique_trade_date[i - rebalance_window - validation_window], unique_trade_date[i - rebalance_window], unique_trade_date))\n",
    "        elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
    "            model_ensemble = model_a2c\n",
    "            model_use.append(('A2C', unique_trade_date[i - rebalance_window - validation_window], unique_trade_date[i - rebalance_window], unique_trade_date))\n",
    "        else:\n",
    "            model_ensemble = model_ddpg\n",
    "            model_use.append(('DDPG', unique_trade_date[i - rebalance_window - validation_window], unique_trade_date[i - rebalance_window], unique_trade_date))\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\n",
    "                                             last_state=last_state_ensemble, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")\n",
    "\n",
    "    sharpe_dict = {'a2c': a2c_sharpe_list, 'ppo': ppo_sharpe_list, 'ddpg': ddpg_sharpe_list}\n",
    "\n",
    "    return sharpe_dict, model_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a82150",
   "metadata": {},
   "source": [
    "##### Our Ensemble Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d23c405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble_strategy_new(df, unique_trade_date, rebalance_window, validation_window) -> None:\n",
    "    last_state_ensemble = []\n",
    "    ppo_sharpe_list = []\n",
    "    sac_sharpe_list = []\n",
    "    td3_sharpe_list = []\n",
    "    \n",
    "    model_use = []\n",
    "    \n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            initial = True\n",
    "        else:\n",
    "            initial = False\n",
    "\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window * 30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \", unique_trade_date[i - rebalance_window - validation_window])\n",
    "\n",
    "        # PROBLEM: DQN NEEDS DISCRETE ACTION SPACE -> ERROR WHEN USING GIVEN ENVS\n",
    "        # Error: see error.txt\n",
    "       \n",
    "        print(\" - PPO Training\")\n",
    "        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=100000)\n",
    "        print(\" - PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_ppo = get_validation_sharpe(i)\n",
    "        print(\" - PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "        \n",
    "        print(\" - SAC Training\")\n",
    "        model_sac = train_SAC(env_train, model_name=\"SAC_35k_dow_{}\".format(i), timesteps=35000)\n",
    "        print(\" - SAC Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_sac, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_sac = get_validation_sharpe(i)\n",
    "        print(\" - SAC Sharpe Ratio: \", sharpe_sac)\n",
    "\n",
    "        print(\" - TD3 Training\")\n",
    "        model_td3 = train_TD3(env_train, model_name=\"TD3_15k_dow_{}\".format(i), timesteps=15000)\n",
    "        print(\" - TD3 Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_td3, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_td3 = get_validation_sharpe(i)\n",
    "        print(\" - TD3 Sharpe Ratio: \", sharpe_td3)\n",
    "\n",
    "        # dqn_sharpe_list.append(sharpe_dqn)\n",
    "        sac_sharpe_list.append(sharpe_sac)\n",
    "        td3_sharpe_list.append(sharpe_td3)\n",
    "        ppo_sharpe_list.append(sharpe_ppo)\n",
    "\n",
    "    \n",
    "        if (sharpe_ppo >= sharpe_sac) & (sharpe_ppo >= sharpe_td3):\n",
    "            model_ensemble = model_ppo\n",
    "            model_use.append('PPO')\n",
    "        elif (sharpe_sac > sharpe_ppo) & (sharpe_sac > sharpe_td3):\n",
    "            model_ensemble = model_sac\n",
    "            model_use.append('SAC')\n",
    "        else:\n",
    "            model_ensemble = model_td3\n",
    "            model_use.append('TD3')\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\n",
    "                                             last_state=last_state_ensemble, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23639922",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20151002\n",
      " - PPO Training\n",
      " - Training time (PPO):  5.985371021429698  minutes\n",
      " - PPO Validation from:  20151002 to  20160104\n",
      " - PPO Sharpe Ratio:  0.031157763712205248\n",
      " - SAC Training\n",
      " - Training time (SAC):  55.82115728457769  minutes\n",
      " - SAC Validation from:  20151002 to  20160104\n",
      " - SAC Sharpe Ratio:  -0.02396180452083464\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.5362343907356262  minutes\n",
      " - TD3 Validation from:  20151002 to  20160104\n",
      " - TD3 Sharpe Ratio:  0.013083692099442762\n",
      " - Trading from:  20160104 to  20160405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1091351.4987812245\n",
      "total_reward:91351.49878122448\n",
      "total_cost:  1919.5141540167244\n",
      "total trades:  913\n",
      "Sharpe:  0.2818473878483306\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20160104\n",
      " - A2C Training\n",
      " - Training time (A2C):  0.9783543626467387  minutes\n",
      " - A2C Validation from:  20160104 to  20160405\n",
      " - A2C Sharpe Ratio:  0.10012659369721663\n",
      " - PPO Training\n",
      " - Training time (PPO):  8.0971462448438  minutes\n",
      " - PPO Validation from:  20160104 to  20160405\n",
      " - PPO Sharpe Ratio:  0.3275527487760709\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.8886476079622905  minutes\n",
      " - DDPG Validation from:  20160104 to  20160405\n",
      " - Trading from:  20160405 to  20160705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1091351.4987812245\n",
      "end_total_asset:1116470.3117230271\n",
      "total_reward:25118.812941802666\n",
      "total_cost:  5015.642772520951\n",
      "total trades:  1470\n",
      "Sharpe:  0.09372295852035431\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160405\n",
      " - A2C Training\n",
      " - Training time (A2C):  2.313125463326772  minutes\n",
      " - A2C Validation from:  20160405 to  20160705\n",
      " - A2C Sharpe Ratio:  0.10739179387434991\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.4454303781191506  minutes\n",
      " - PPO Validation from:  20160405 to  20160705\n",
      " - PPO Sharpe Ratio:  0.06829417255684964\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6234971563021342  minutes\n",
      " - DDPG Validation from:  20160405 to  20160705\n",
      " - Trading from:  20160705 to  20161003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1116470.3117230271\n",
      "end_total_asset:1102004.9750411054\n",
      "total_reward:-14465.336681921734\n",
      "total_cost:  1517.713811089555\n",
      "total trades:  1042\n",
      "Sharpe:  -0.056911822908928426\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0360590855280558  minutes\n",
      " - A2C Validation from:  20160705 to  20161003\n",
      " - A2C Sharpe Ratio:  -0.049477746297428064\n",
      " - PPO Training\n",
      " - Training time (PPO):  9.539967799186707  minutes\n",
      " - PPO Validation from:  20160705 to  20161003\n",
      " - PPO Sharpe Ratio:  0.13629749878954725\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.8660128355026244  minutes\n",
      " - DDPG Validation from:  20160705 to  20161003\n",
      " - Trading from:  20161003 to  20170103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1102004.9750411054\n",
      "end_total_asset:1132012.9902395385\n",
      "total_reward:30008.015198433073\n",
      "total_cost:  3093.0054304128125\n",
      "total trades:  1333\n",
      "Sharpe:  0.14328608964277129\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20161003\n",
      " - A2C Training\n",
      " - Training time (A2C):  3.101040764649709  minutes\n",
      " - A2C Validation from:  20161003 to  20170103\n",
      " - A2C Sharpe Ratio:  0.35906276584517854\n",
      " - PPO Training\n",
      " - Training time (PPO):  5.197341275215149  minutes\n",
      " - PPO Validation from:  20161003 to  20170103\n",
      " - PPO Sharpe Ratio:  0.44474971360699195\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.7239963332811992  minutes\n",
      " - DDPG Validation from:  20161003 to  20170103\n",
      " - Trading from:  20170103 to  20170404\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1132012.9902395385\n",
      "end_total_asset:1104984.9966841473\n",
      "total_reward:-27027.993555391207\n",
      "total_cost:  4398.96763678306\n",
      "total trades:  1372\n",
      "Sharpe:  -0.14068823554952078\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20170103\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.1271788597106933  minutes\n",
      " - A2C Validation from:  20170103 to  20170404\n",
      " - A2C Sharpe Ratio:  0.1991038449714915\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.952379969755809  minutes\n",
      " - PPO Validation from:  20170103 to  20170404\n",
      " - PPO Sharpe Ratio:  0.29239303273308814\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.803309683005015  minutes\n",
      " - DDPG Validation from:  20170103 to  20170404\n",
      " - Trading from:  20170404 to  20170705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1104984.9966841473\n",
      "end_total_asset:1135693.2856350092\n",
      "total_reward:30708.288950861897\n",
      "total_cost:  6041.535623151707\n",
      "total trades:  1215\n",
      "Sharpe:  0.19062866804321965\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170404\n",
      " - A2C Training\n",
      " - Training time (A2C):  3.2545403401056925  minutes\n",
      " - A2C Validation from:  20170404 to  20170705\n",
      " - A2C Sharpe Ratio:  0.09178408486325434\n",
      " - PPO Training\n",
      " - Training time (PPO):  4.935455624262492  minutes\n",
      " - PPO Validation from:  20170404 to  20170705\n",
      " - PPO Sharpe Ratio:  0.21907219768024336\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.9311413327852884  minutes\n",
      " - DDPG Validation from:  20170404 to  20170705\n",
      " - Trading from:  20170705 to  20171003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1135693.2856350092\n",
      "end_total_asset:1212698.3235845773\n",
      "total_reward:77005.03794956813\n",
      "total_cost:  2347.3414453145992\n",
      "total trades:  964\n",
      "Sharpe:  0.4797560516730028\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170705\n",
      " - A2C Training\n",
      " - Training time (A2C):  2.822346007823944  minutes\n",
      " - A2C Validation from:  20170705 to  20171003\n",
      " - A2C Sharpe Ratio:  0.317909219365062\n",
      " - PPO Training\n",
      " - Training time (PPO):  5.76781607468923  minutes\n",
      " - PPO Validation from:  20170705 to  20171003\n",
      " - PPO Sharpe Ratio:  0.3997823036552423\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6441254019737244  minutes\n",
      " - DDPG Validation from:  20170705 to  20171003\n",
      " - Trading from:  20171003 to  20180103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1212698.3235845773\n",
      "end_total_asset:1363167.7891384298\n",
      "total_reward:150469.4655538525\n",
      "total_cost:  3917.861711195952\n",
      "total trades:  1151\n",
      "Sharpe:  0.657835845443021\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20171003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.2236281752586364  minutes\n",
      " - A2C Validation from:  20171003 to  20180103\n",
      " - A2C Sharpe Ratio:  0.4542555843975292\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.8731875975926715  minutes\n",
      " - PPO Validation from:  20171003 to  20180103\n",
      " - PPO Sharpe Ratio:  0.4813587773737356\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.8857900381088257  minutes\n",
      " - DDPG Validation from:  20171003 to  20180103\n",
      " - Trading from:  20180103 to  20180405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1363167.7891384298\n",
      "end_total_asset:1384488.4728828277\n",
      "total_reward:21320.683744397946\n",
      "total_cost:  1702.179552639323\n",
      "total trades:  233\n",
      "Sharpe:  0.08824333343410136\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180103\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.1113980213801067  minutes\n",
      " - A2C Validation from:  20180103 to  20180405\n",
      " - A2C Sharpe Ratio:  -0.019102160149480494\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.926926914850871  minutes\n",
      " - PPO Validation from:  20180103 to  20180405\n",
      " - PPO Sharpe Ratio:  0.016991388916857676\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6205780466397604  minutes\n",
      " - DDPG Validation from:  20180103 to  20180405\n",
      " - Trading from:  20180405 to  20180705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1384488.4728828277\n",
      "end_total_asset:1376312.1485445076\n",
      "total_reward:-8176.324338320177\n",
      "total_cost:  5963.3362126941365\n",
      "total trades:  1047\n",
      "Sharpe:  -0.02993743091754576\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180405\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.1462910731633504  minutes\n",
      " - A2C Validation from:  20180405 to  20180705\n",
      " - A2C Sharpe Ratio:  0.026190043936852418\n",
      " - PPO Training\n",
      " - Training time (PPO):  4.610698421796163  minutes\n",
      " - PPO Validation from:  20180405 to  20180705\n",
      " - PPO Sharpe Ratio:  -0.025866355686047993\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.9561887860298157  minutes\n",
      " - DDPG Validation from:  20180405 to  20180705\n",
      " - Trading from:  20180705 to  20181003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1376312.1485445076\n",
      "end_total_asset:1381836.2769321096\n",
      "total_reward:5524.128387602046\n",
      "total_cost:  5965.592355033372\n",
      "total trades:  904\n",
      "Sharpe:  0.05098995998624212\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0401576598485311  minutes\n",
      " - A2C Validation from:  20180705 to  20181003\n",
      " - A2C Sharpe Ratio:  0.20405083049962588\n",
      " - PPO Training\n",
      " - Training time (PPO):  4.169330461819967  minutes\n",
      " - PPO Validation from:  20180705 to  20181003\n",
      " - PPO Sharpe Ratio:  0.039733433400822395\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6552011887232463  minutes\n",
      " - DDPG Validation from:  20180705 to  20181003\n",
      " - Trading from:  20181003 to  20190104\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1381836.2769321096\n",
      "end_total_asset:1386090.1930870672\n",
      "total_reward:4253.916154957609\n",
      "total_cost:  726.4556761630249\n",
      "total trades:  102\n",
      "Sharpe:  0.1009793282754426\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20181003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.4716258287429809  minutes\n",
      " - A2C Validation from:  20181003 to  20190104\n",
      " - A2C Sharpe Ratio:  -0.29984473256900745\n",
      " - PPO Training\n",
      " - Training time (PPO):  7.514733175436656  minutes\n",
      " - PPO Validation from:  20181003 to  20190104\n",
      " - PPO Sharpe Ratio:  -0.34281547906838244\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.7124886949857077  minutes\n",
      " - DDPG Validation from:  20181003 to  20190104\n",
      " - Trading from:  20190104 to  20190405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1386090.1930870672\n",
      "end_total_asset:1515755.4175810902\n",
      "total_reward:129665.22449402302\n",
      "total_cost:  7235.246953319538\n",
      "total trades:  1349\n",
      "Sharpe:  0.45042619100656306\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190104\n",
      " - A2C Training\n",
      " - Training time (A2C):  3.201207399368286  minutes\n",
      " - A2C Validation from:  20190104 to  20190405\n",
      " - A2C Sharpe Ratio:  0.010562642401028452\n",
      " - PPO Training\n",
      " - Training time (PPO):  4.135537052154541  minutes\n",
      " - PPO Validation from:  20190104 to  20190405\n",
      " - PPO Sharpe Ratio:  -0.09808503009632923\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6060652494430542  minutes\n",
      " - DDPG Validation from:  20190104 to  20190405\n",
      " - Trading from:  20190405 to  20190708\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1515755.4175810902\n",
      "end_total_asset:1526710.0464575638\n",
      "total_reward:10954.628876473522\n",
      "total_cost:  1213.7988452145148\n",
      "total trades:  128\n",
      "Sharpe:  0.4275309186608869\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190405\n",
      " - A2C Training\n",
      " - Training time (A2C):  2.92970583041509  minutes\n",
      " - A2C Validation from:  20190405 to  20190708\n",
      " - A2C Sharpe Ratio:  0.15403028209209685\n",
      " - PPO Training\n",
      " - Training time (PPO):  10.254123477141063  minutes\n",
      " - PPO Validation from:  20190405 to  20190708\n",
      " - PPO Sharpe Ratio:  0.014543986336784588\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6020244638125102  minutes\n",
      " - DDPG Validation from:  20190405 to  20190708\n",
      " - Trading from:  20190708 to  20191004\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1526710.0464575638\n",
      "end_total_asset:1532984.6410278257\n",
      "total_reward:6274.594570261892\n",
      "total_cost:  1586.3598575542621\n",
      "total trades:  346\n",
      "Sharpe:  0.13213440775172414\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190708\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.6847307721773783  minutes\n",
      " - A2C Validation from:  20190708 to  20191004\n",
      " - A2C Sharpe Ratio:  0.15389981634757666\n",
      " - PPO Training\n",
      " - Training time (PPO):  8.21238714059194  minutes\n",
      " - PPO Validation from:  20190708 to  20191004\n",
      " - PPO Sharpe Ratio:  0.012075421840213409\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  2.0333690524101256  minutes\n",
      " - DDPG Validation from:  20190708 to  20191004\n",
      " - Trading from:  20191004 to  20200106\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1532984.6410278257\n",
      "end_total_asset:1532380.4676305498\n",
      "total_reward:-604.173397275852\n",
      "total_cost:  353.5924248679972\n",
      "total trades:  74\n",
      "Sharpe:  -0.12800516798138456\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20191004\n",
      " - A2C Training\n",
      " - Training time (A2C):  4.1561951796213785  minutes\n",
      " - A2C Validation from:  20191004 to  20200106\n",
      " - A2C Sharpe Ratio:  -0.19068288537306166\n",
      " - PPO Training\n",
      " - Training time (PPO):  14.568490942319235  minutes\n",
      " - PPO Validation from:  20191004 to  20200106\n",
      " - PPO Sharpe Ratio:  -0.17013076871389382\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  1.9112040758132935  minutes\n",
      " - DDPG Validation from:  20191004 to  20200106\n",
      " - Trading from:  20200106 to  20200406\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1532380.4676305498\n",
      "end_total_asset:1508979.9515341038\n",
      "total_reward:-23400.516096445965\n",
      "total_cost:  1316.1191736628718\n",
      "total trades:  163\n",
      "Sharpe:  -0.3870524660877592\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20200106\n",
      " - A2C Training\n",
      " - Training time (A2C):  2.2424469312032063  minutes\n",
      " - A2C Validation from:  20200106 to  20200406\n",
      " - A2C Sharpe Ratio:  -0.47548938917599864\n",
      " - PPO Training\n",
      " - Training time (PPO):  6.747341891129811  minutes\n",
      " - PPO Validation from:  20200106 to  20200406\n",
      " - PPO Sharpe Ratio:  -0.4143404457413655\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.9985157608985901  minutes\n",
      " - DDPG Validation from:  20200106 to  20200406\n",
      " - Trading from:  20200406 to  20200707\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1508979.9515341038\n",
      "end_total_asset:1514375.1088136525\n",
      "total_reward:5395.157279548701\n",
      "total_cost:  511.34665691185006\n",
      "total trades:  78\n",
      "Sharpe:  0.2470473453991146\n",
      "Ensemble Strategy took:  173.57000953753789  minutes\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "sharpe_dict, model_use_lst = run_ensemble_strategy(df=df, unique_trade_date=unique_trade_date, rebalance_window=rebalance_window, validation_window=validation_window)\n",
    "\n",
    "with open('working/sharpe_dict.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write header\n",
    "    writer.writerow(sharpe_dict.keys())\n",
    "    \n",
    "    # Write rows\n",
    "    writer.writerows(zip(*sharpe_dict.values()))\n",
    "\n",
    "headers = ['Model', 'Validation_Begin', 'Validation_End/Trade_Begin', 'Trade_End']\n",
    "\n",
    "with open('working/output.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Write the data\n",
    "    writer.writerows(model_use_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6000bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ppo(df, unique_trade_date, rebalance_window, validation_window):\n",
    "    ppo_sharpe_list = []\n",
    "    last_state_ppo = []\n",
    "\n",
    "\n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            # inital state\n",
    "            initial = True\n",
    "        else:\n",
    "            # previous state\n",
    "            initial = False\n",
    "\n",
    "        # Tuning trubulence index based on historical data\n",
    "        # Turbulence lookback window is one quarter\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window*30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "            # then we assume that the current market is volatile,\n",
    "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        ## validation env\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \",\n",
    "              unique_trade_date[i - rebalance_window - validation_window])\n",
    "\n",
    "        print(\" - PPO Training\")\n",
    "        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=100000)\n",
    "        print(\" - PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_ppo = get_validation_sharpe(i)\n",
    "        print(\" - PPO Sharpe Ratio: \", sharpe_ppo)\n",
    "\n",
    "        ppo_sharpe_list.append(sharpe_ppo)\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_ppo = DRL_prediction(df=df, model=model_ppo, name=\"ensemble\",\n",
    "                                             last_state=last_state_ppo, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")\n",
    "\n",
    "    return ppo_sharpe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2348da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ddpg(df, unique_trade_date, rebalance_window, validation_window):\n",
    "    ddpg_sharpe_list = []\n",
    "    last_state_ddpg = []\n",
    "\n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            # inital state\n",
    "            initial = True\n",
    "        else:\n",
    "            # previous state\n",
    "            initial = False\n",
    "\n",
    "        # Tuning trubulence index based on historical data\n",
    "        # Turbulence lookback window is one quarter\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window*30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "            # then we assume that the current market is volatile,\n",
    "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        ## validation env\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \",\n",
    "              unique_trade_date[i - rebalance_window - validation_window])\n",
    "\n",
    "        print(\" - DDPG Training\")\n",
    "        model_ddpg = train_DDPG(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=10000)\n",
    "        print(\" - DDPG Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_ddpg, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_ddpg = get_validation_sharpe(i)\n",
    "        print(\" - DDPG Sharpe Ratio: \", sharpe_ddpg)\n",
    "\n",
    "        ddpg_sharpe_list.append(sharpe_ddpg)\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_ddpg = DRL_prediction(df=df, model=model_ddpg, name=\"ensemble\",\n",
    "                                             last_state=last_state_ddpg, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"DDPG Strategy took: \", (end - start) / 60, \" minutes\")\n",
    "\n",
    "    return ddpg_sharpe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf2cf3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20151002\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.1259528915087382  minutes\n",
      " - PPO Validation from:  20151002 to  20160104\n",
      " - PPO Sharpe Ratio:  0.0031336893879767556\n",
      " - Trading from:  20160104 to  20160405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1082664.5934531197\n",
      "total_reward:82664.59345311974\n",
      "total_cost:  5277.811792154926\n",
      "total trades:  1379\n",
      "Sharpe:  0.3160765849955953\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20160104\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.2428390264511107  minutes\n",
      " - PPO Validation from:  20160104 to  20160405\n",
      " - PPO Sharpe Ratio:  0.006890802775974063\n",
      " - Trading from:  20160405 to  20160705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1082664.5934531197\n",
      "end_total_asset:1046475.9347600612\n",
      "total_reward:-36188.65869305853\n",
      "total_cost:  4812.1951698457015\n",
      "total trades:  1371\n",
      "Sharpe:  -0.11677813782280697\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160405\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.277379616101583  minutes\n",
      " - PPO Validation from:  20160405 to  20160705\n",
      " - PPO Sharpe Ratio:  0.014637587724390664\n",
      " - Trading from:  20160705 to  20161003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1046475.9347600612\n",
      "end_total_asset:1086558.3645639\n",
      "total_reward:40082.42980383884\n",
      "total_cost:  5596.2989561459635\n",
      "total trades:  1495\n",
      "Sharpe:  0.17873419164407361\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160705\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.291174062093099  minutes\n",
      " - PPO Validation from:  20160705 to  20161003\n",
      " - PPO Sharpe Ratio:  0.03221948517633894\n",
      " - Trading from:  20161003 to  20170103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1086558.3645639\n",
      "end_total_asset:1162652.3267759227\n",
      "total_reward:76093.96221202263\n",
      "total_cost:  2537.7660434031645\n",
      "total trades:  1286\n",
      "Sharpe:  0.38204058673591934\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20161003\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.314630659421285  minutes\n",
      " - PPO Validation from:  20161003 to  20170103\n",
      " - PPO Sharpe Ratio:  0.4809989915861936\n",
      " - Trading from:  20170103 to  20170404\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1162652.3267759227\n",
      "end_total_asset:1197565.6246248323\n",
      "total_reward:34913.29784890963\n",
      "total_cost:  3811.26677679614\n",
      "total trades:  1356\n",
      "Sharpe:  0.15772863507811918\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20170103\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.297233847777049  minutes\n",
      " - PPO Validation from:  20170103 to  20170404\n",
      " - PPO Sharpe Ratio:  0.4379220613802391\n",
      " - Trading from:  20170404 to  20170705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1197565.6246248323\n",
      "end_total_asset:1219056.3121250204\n",
      "total_reward:21490.687500188127\n",
      "total_cost:  5644.1498860968995\n",
      "total trades:  1167\n",
      "Sharpe:  0.1477112455277392\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170404\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.3478524327278136  minutes\n",
      " - PPO Validation from:  20170404 to  20170705\n",
      " - PPO Sharpe Ratio:  0.3159694077126126\n",
      " - Trading from:  20170705 to  20171003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1219056.3121250204\n",
      "end_total_asset:1245649.9111726861\n",
      "total_reward:26593.599047665717\n",
      "total_cost:  8270.448036400976\n",
      "total trades:  1506\n",
      "Sharpe:  0.18604866893195224\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170705\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.3586754480997723  minutes\n",
      " - PPO Validation from:  20170705 to  20171003\n",
      " - PPO Sharpe Ratio:  0.09336864632666345\n",
      " - Trading from:  20171003 to  20180103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1245649.9111726861\n",
      "end_total_asset:1349317.432692529\n",
      "total_reward:103667.52151984279\n",
      "total_cost:  8272.334971450522\n",
      "total trades:  1596\n",
      "Sharpe:  0.5744915571600165\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20171003\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.3370216290156045  minutes\n",
      " - PPO Validation from:  20171003 to  20180103\n",
      " - PPO Sharpe Ratio:  0.4844236246027877\n",
      " - Trading from:  20180103 to  20180405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1349317.432692529\n",
      "end_total_asset:1373645.7269045226\n",
      "total_reward:24328.294211993692\n",
      "total_cost:  2587.8568045278566\n",
      "total trades:  383\n",
      "Sharpe:  0.13124198526083386\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180103\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.370074431101481  minutes\n",
      " - PPO Validation from:  20180103 to  20180405\n",
      " - PPO Sharpe Ratio:  0.007848752011157725\n",
      " - Trading from:  20180405 to  20180705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1373645.7269045226\n",
      "end_total_asset:1371847.7844413603\n",
      "total_reward:-1797.9424631623551\n",
      "total_cost:  6906.965273839124\n",
      "total trades:  1074\n",
      "Sharpe:  -0.0019069218412103783\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180405\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.3661951224009194  minutes\n",
      " - PPO Validation from:  20180405 to  20180705\n",
      " - PPO Sharpe Ratio:  -0.03935125734793043\n",
      " - Trading from:  20180705 to  20181003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1371847.7844413603\n",
      "end_total_asset:1394440.6936602741\n",
      "total_reward:22592.909218913876\n",
      "total_cost:  5594.340273017777\n",
      "total trades:  889\n",
      "Sharpe:  0.2382927708088126\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180705\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.4636390527089436  minutes\n",
      " - PPO Validation from:  20180705 to  20181003\n",
      " - PPO Sharpe Ratio:  0.1088194910400448\n",
      " - Trading from:  20181003 to  20190104\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1394440.6936602741\n",
      "end_total_asset:1398281.71142694\n",
      "total_reward:3841.0177666659\n",
      "total_cost:  633.499727937967\n",
      "total trades:  139\n",
      "Sharpe:  0.1775239105845042\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20181003\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.480057426293691  minutes\n",
      " - PPO Validation from:  20181003 to  20190104\n",
      " - PPO Sharpe Ratio:  -0.4095779227395506\n",
      " - Trading from:  20190104 to  20190405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1398281.71142694\n",
      "end_total_asset:1456271.484572064\n",
      "total_reward:57989.77314512385\n",
      "total_cost:  5992.323400517667\n",
      "total trades:  1362\n",
      "Sharpe:  0.1925882802550712\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190104\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.445944094657898  minutes\n",
      " - PPO Validation from:  20190104 to  20190405\n",
      " - PPO Sharpe Ratio:  0.043489997121122885\n",
      " - Trading from:  20190405 to  20190708\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1456271.484572064\n",
      "end_total_asset:1458406.535958571\n",
      "total_reward:2135.051386506995\n",
      "total_cost:  1043.7625133687854\n",
      "total trades:  138\n",
      "Sharpe:  0.17768102518788037\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190405\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.4580403447151182  minutes\n",
      " - PPO Validation from:  20190405 to  20190708\n",
      " - PPO Sharpe Ratio:  0.3050054747830708\n",
      " - Trading from:  20190708 to  20191004\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1458406.535958571\n",
      "end_total_asset:1457036.63526226\n",
      "total_reward:-1369.9006963109132\n",
      "total_cost:  1615.368345909031\n",
      "total trades:  319\n",
      "Sharpe:  -0.040888848141313695\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190708\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.4671496589978537  minutes\n",
      " - PPO Validation from:  20190708 to  20191004\n",
      " - PPO Sharpe Ratio:  -0.044979031837063296\n",
      " - Trading from:  20191004 to  20200106\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1457036.63526226\n",
      "end_total_asset:1457013.8383197794\n",
      "total_reward:-22.79694248060696\n",
      "total_cost:  260.6072977482748\n",
      "total trades:  58\n",
      "Sharpe:  -0.005672586525488364\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20191004\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.4650422016779583  minutes\n",
      " - PPO Validation from:  20191004 to  20200106\n",
      " - PPO Sharpe Ratio:  -0.3465762254706126\n",
      " - Trading from:  20200106 to  20200406\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1457013.8383197794\n",
      "end_total_asset:1439556.2743047173\n",
      "total_reward:-17457.56401506206\n",
      "total_cost:  916.6900985847525\n",
      "total trades:  165\n",
      "Sharpe:  -0.38973550129997364\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20200106\n",
      " - PPO Training\n",
      " - Training time (PPO):  3.489498221874237  minutes\n",
      " - PPO Validation from:  20200106 to  20200406\n",
      " - PPO Sharpe Ratio:  -0.4734399720239065\n",
      " - Trading from:  20200406 to  20200707\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1439556.2743047173\n",
      "end_total_asset:1441059.8200284294\n",
      "total_reward:1503.5457237120718\n",
      "total_cost:  459.87905724596493\n",
      "total trades:  116\n",
      "Sharpe:  0.15482819815748533\n",
      "Ensemble Strategy took:  60.69662701686223  minutes\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12524\\1643512071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'working/ppo_sharpe_list.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Write the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "ppo_sharpe_lst = run_ppo(df=df, unique_trade_date=unique_trade_date, rebalance_window=rebalance_window, validation_window=validation_window)\n",
    "\n",
    "with open('working/ppo_sharpe_list.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerows(ppo_sharpe_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c57a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0031336893879767556, 0.006890802775974063, 0.014637587724390664, 0.03221948517633894, 0.4809989915861936, 0.4379220613802391, 0.3159694077126126, 0.09336864632666345, 0.4844236246027877, 0.007848752011157725, -0.03935125734793043, 0.1088194910400448, -0.4095779227395506, 0.043489997121122885, 0.3050054747830708, -0.044979031837063296, -0.3465762254706126, -0.4734399720239065]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "print(ppo_sharpe_lst)\n",
    "\n",
    "with open('working_ppo/ppo_sharpe_list.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerow(ppo_sharpe_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4348544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20151002\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.49127381245295204  minutes\n",
      " - DDPG Validation from:  20151002 to  20160104\n",
      " - DDPG Sharpe Ratio:  -0.022949790132500977\n",
      " - Trading from:  20160104 to  20160405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1087838.3974220427\n",
      "total_reward:87838.39742204268\n",
      "total_cost:  1263.5199797485827\n",
      "total trades:  614\n",
      "Sharpe:  0.24626882699080646\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20160104\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.48677930037180583  minutes\n",
      " - DDPG Validation from:  20160104 to  20160405\n",
      " - DDPG Sharpe Ratio:  -0.0009580415677292225\n",
      " - Trading from:  20160405 to  20160705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1087838.3974220427\n",
      "end_total_asset:1060816.1229146663\n",
      "total_reward:-27022.274507376365\n",
      "total_cost:  1735.354613832899\n",
      "total trades:  709\n",
      "Sharpe:  -0.06116620230987619\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160405\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5057465632756551  minutes\n",
      " - DDPG Validation from:  20160405 to  20160705\n",
      " - DDPG Sharpe Ratio:  0.12354199196719107\n",
      " - Trading from:  20160705 to  20161003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1060816.1229146663\n",
      "end_total_asset:1090471.0556113627\n",
      "total_reward:29654.93269669637\n",
      "total_cost:  720.2810874972919\n",
      "total trades:  1052\n",
      "Sharpe:  0.11985893621893072\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160705\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5231726884841919  minutes\n",
      " - DDPG Validation from:  20160705 to  20161003\n",
      " - DDPG Sharpe Ratio:  -0.18404285271812995\n",
      " - Trading from:  20161003 to  20170103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1090471.0556113627\n",
      "end_total_asset:1225838.830124174\n",
      "total_reward:135367.77451281133\n",
      "total_cost:  1778.4553584931944\n",
      "total trades:  1081\n",
      "Sharpe:  0.5887593721799421\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20161003\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5127113660176595  minutes\n",
      " - DDPG Validation from:  20161003 to  20170103\n",
      " - DDPG Sharpe Ratio:  0.6067515994947491\n",
      " - Trading from:  20170103 to  20170404\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1225838.830124174\n",
      "end_total_asset:1248056.2958349544\n",
      "total_reward:22217.46571078035\n",
      "total_cost:  2199.8181047135445\n",
      "total trades:  1110\n",
      "Sharpe:  0.10506553707534409\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20170103\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5197319825490315  minutes\n",
      " - DDPG Validation from:  20170103 to  20170404\n",
      " - DDPG Sharpe Ratio:  0.5199284268257167\n",
      " - Trading from:  20170404 to  20170705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1248056.2958349544\n",
      "end_total_asset:1285058.4808053474\n",
      "total_reward:37002.18497039308\n",
      "total_cost:  3453.8862194996864\n",
      "total trades:  957\n",
      "Sharpe:  0.2548225971460972\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170404\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5203472733497619  minutes\n",
      " - DDPG Validation from:  20170404 to  20170705\n",
      " - DDPG Sharpe Ratio:  0.22235406739162197\n",
      " - Trading from:  20170705 to  20171003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1285058.4808053474\n",
      "end_total_asset:1315586.1693143223\n",
      "total_reward:30527.688508974854\n",
      "total_cost:  2740.987255720563\n",
      "total trades:  1062\n",
      "Sharpe:  0.17947468349230722\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170705\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5317955493927002  minutes\n",
      " - DDPG Validation from:  20170705 to  20171003\n",
      " - DDPG Sharpe Ratio:  0.3143547164187303\n",
      " - Trading from:  20171003 to  20180103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1315586.1693143223\n",
      "end_total_asset:1482107.9408819033\n",
      "total_reward:166521.771567581\n",
      "total_cost:  1941.717305686931\n",
      "total trades:  807\n",
      "Sharpe:  0.8043868786022077\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20171003\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5211214264233907  minutes\n",
      " - DDPG Validation from:  20171003 to  20180103\n",
      " - DDPG Sharpe Ratio:  0.4287320122066053\n",
      " - Trading from:  20180103 to  20180405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1482107.9408819033\n",
      "end_total_asset:1522620.4643265386\n",
      "total_reward:40512.52344463533\n",
      "total_cost:  2036.1523489205272\n",
      "total trades:  216\n",
      "Sharpe:  0.18136395600733052\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180103\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6514056007067363  minutes\n",
      " - DDPG Validation from:  20180103 to  20180405\n",
      " - DDPG Sharpe Ratio:  -0.025285708380577056\n",
      " - Trading from:  20180405 to  20180705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1522620.4643265386\n",
      "end_total_asset:1541513.0470279695\n",
      "total_reward:18892.58270143089\n",
      "total_cost:  3159.3672308105083\n",
      "total trades:  715\n",
      "Sharpe:  0.06651107319486108\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180405\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6083440542221069  minutes\n",
      " - DDPG Validation from:  20180405 to  20180705\n",
      " - DDPG Sharpe Ratio:  0.17927162996885035\n",
      " - Trading from:  20180705 to  20181003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1541513.0470279695\n",
      "end_total_asset:1577871.6223943017\n",
      "total_reward:36358.575366332196\n",
      "total_cost:  4670.773522216444\n",
      "total trades:  536\n",
      "Sharpe:  0.31268191671920287\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180705\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.6155606706937155  minutes\n",
      " - DDPG Validation from:  20180705 to  20181003\n",
      " - DDPG Sharpe Ratio:  0.17153925223003844\n",
      " - Trading from:  20181003 to  20190104\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1577871.6223943017\n",
      "end_total_asset:1589086.3560633026\n",
      "total_reward:11214.73366900091\n",
      "total_cost:  1369.0468661515176\n",
      "total trades:  152\n",
      "Sharpe:  0.14718883251018422\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20181003\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.619461194674174  minutes\n",
      " - DDPG Validation from:  20181003 to  20190104\n",
      " - DDPG Sharpe Ratio:  -0.3552655055566505\n",
      " - Trading from:  20190104 to  20190405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1589086.3560633026\n",
      "end_total_asset:1565417.7561055343\n",
      "total_reward:-23668.59995776834\n",
      "total_cost:  3519.7002012851835\n",
      "total trades:  1166\n",
      "Sharpe:  -0.013348468747135906\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190104\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  42.326098497708635  minutes\n",
      " - DDPG Validation from:  20190104 to  20190405\n",
      " - DDPG Sharpe Ratio:  0.08596169671992866\n",
      " - Trading from:  20190405 to  20190708\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1565417.7561055343\n",
      "end_total_asset:1571449.5825414432\n",
      "total_reward:6031.826435908908\n",
      "total_cost:  1075.7824445611575\n",
      "total trades:  106\n",
      "Sharpe:  0.1963629205588974\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190405\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5519924402236939  minutes\n",
      " - DDPG Validation from:  20190405 to  20190708\n",
      " - DDPG Sharpe Ratio:  0.28339376602712596\n",
      " - Trading from:  20190708 to  20191004\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1571449.5825414432\n",
      "end_total_asset:1568440.7568613435\n",
      "total_reward:-3008.8256800996605\n",
      "total_cost:  2117.5096307632016\n",
      "total trades:  250\n",
      "Sharpe:  -0.05662051401739093\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190708\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5729690551757812  minutes\n",
      " - DDPG Validation from:  20190708 to  20191004\n",
      " - DDPG Sharpe Ratio:  -0.011772928018477407\n",
      " - Trading from:  20191004 to  20200106\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1568440.7568613435\n",
      "end_total_asset:1569022.6144972318\n",
      "total_reward:581.857635888271\n",
      "total_cost:  244.4003614527893\n",
      "total trades:  48\n",
      "Sharpe:  0.11187989304120219\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20191004\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5660956819852193  minutes\n",
      " - DDPG Validation from:  20191004 to  20200106\n",
      " - DDPG Sharpe Ratio:  -0.3751868820661148\n",
      " - Trading from:  20200106 to  20200406\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1569022.6144972318\n",
      "end_total_asset:1549507.2697522754\n",
      "total_reward:-19515.344744956354\n",
      "total_cost:  981.6753884419918\n",
      "total trades:  151\n",
      "Sharpe:  -0.43068584562278533\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20200106\n",
      " - DDPG Training\n",
      " - Training time (DDPG):  0.5790685574213664  minutes\n",
      " - DDPG Validation from:  20200106 to  20200406\n",
      " - DDPG Sharpe Ratio:  -0.38495609884641374\n",
      " - Trading from:  20200406 to  20200707\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1549507.2697522754\n",
      "end_total_asset:1552380.7402522787\n",
      "total_reward:2873.4705000033136\n",
      "total_cost:  674.774142339363\n",
      "total trades:  107\n",
      "Sharpe:  0.16108421263450604\n",
      "DDPG Strategy took:  51.837209177017215  minutes\n"
     ]
    }
   ],
   "source": [
    "ddpg_sharpe_lst = run_ddpg(df=df, unique_trade_date=unique_trade_date, rebalance_window=rebalance_window, validation_window=validation_window)\n",
    "\n",
    "with open('working/ddpg_sharpe_list.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerow(ddpg_sharpe_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c02e00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a2c(df, unique_trade_date, rebalance_window, validation_window):\n",
    "    a2c_sharpe_list = []\n",
    "    last_state_a2c = []\n",
    "\n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            # inital state\n",
    "            initial = True\n",
    "        else:\n",
    "            # previous state\n",
    "            initial = False\n",
    "\n",
    "        # Tuning trubulence index based on historical data\n",
    "        # Turbulence lookback window is one quarter\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window*30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "            # then we assume that the current market is volatile,\n",
    "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        ## validation env\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \",\n",
    "              unique_trade_date[i - rebalance_window - validation_window])\n",
    "\n",
    "        print(\" - A2C Training\")\n",
    "        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i), timesteps=30000)\n",
    "        print(\" - A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_a2c = get_validation_sharpe(i)\n",
    "        print(\" - A2C Sharpe Ratio: \", sharpe_a2c)\n",
    "\n",
    "        a2c_sharpe_list.append(sharpe_a2c)\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_a2c = DRL_prediction(df=df, model=model_a2c, name=\"ensemble\",\n",
    "                                             last_state=last_state_a2c, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"A2C Strategy took: \", (end - start) / 60, \" minutes\")\n",
    "\n",
    "    return a2c_sharpe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf9b36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20151002\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.253728727499644  minutes\n",
      " - A2C Validation from:  20151002 to  20160104\n",
      " - A2C Sharpe Ratio:  0.012806212433986608\n",
      " - Trading from:  20160104 to  20160405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1059335.8341400342\n",
      "total_reward:59335.83414003416\n",
      "total_cost:  4368.7422587062\n",
      "total trades:  1456\n",
      "Sharpe:  0.19581729684435253\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20160104\n",
      " - A2C Training\n",
      " - Training time (A2C):  2.824491242567698  minutes\n",
      " - A2C Validation from:  20160104 to  20160405\n",
      " - A2C Sharpe Ratio:  0.21363374539632812\n",
      " - Trading from:  20160405 to  20160705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1059335.8341400342\n",
      "end_total_asset:1100538.014982359\n",
      "total_reward:41202.18084232486\n",
      "total_cost:  6097.118760408079\n",
      "total trades:  1386\n",
      "Sharpe:  0.17321137273787424\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160405\n",
      " - A2C Training\n",
      " - Training time (A2C):  2.7450753887494406  minutes\n",
      " - A2C Validation from:  20160405 to  20160705\n",
      " - A2C Sharpe Ratio:  0.11447049829835196\n",
      " - Trading from:  20160705 to  20161003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1100538.014982359\n",
      "end_total_asset:1089124.3216326472\n",
      "total_reward:-11413.69334971183\n",
      "total_cost:  2042.0148675072105\n",
      "total trades:  1218\n",
      "Sharpe:  -0.04494789480691039\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.1794536590576172  minutes\n",
      " - A2C Validation from:  20160705 to  20161003\n",
      " - A2C Sharpe Ratio:  0.02040440234629556\n",
      " - Trading from:  20161003 to  20170103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1089124.3216326472\n",
      "end_total_asset:1144158.897580025\n",
      "total_reward:55034.57594737783\n",
      "total_cost:  4651.736489707134\n",
      "total trades:  1483\n",
      "Sharpe:  0.2748768455635501\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20161003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.01000927289327  minutes\n",
      " - A2C Validation from:  20161003 to  20170103\n",
      " - A2C Sharpe Ratio:  0.27267425355576674\n",
      " - Trading from:  20170103 to  20170404\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1144158.897580025\n",
      "end_total_asset:1145170.819413328\n",
      "total_reward:1011.9218333030585\n",
      "total_cost:  2179.6684697851415\n",
      "total trades:  1206\n",
      "Sharpe:  0.010589658549174713\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20170103\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.034466544787089  minutes\n",
      " - A2C Validation from:  20170103 to  20170404\n",
      " - A2C Sharpe Ratio:  0.18235132588851802\n",
      " - Trading from:  20170404 to  20170705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1145170.819413328\n",
      "end_total_asset:1178255.4078551882\n",
      "total_reward:33084.58844186016\n",
      "total_cost:  6193.6087012359185\n",
      "total trades:  1274\n",
      "Sharpe:  0.2726476357439106\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170404\n",
      " - A2C Training\n",
      " - Training time (A2C):  0.9974902828534444  minutes\n",
      " - A2C Validation from:  20170404 to  20170705\n",
      " - A2C Sharpe Ratio:  0.23640926038795843\n",
      " - Trading from:  20170705 to  20171003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1178255.4078551882\n",
      "end_total_asset:1265908.8893056754\n",
      "total_reward:87653.48145048716\n",
      "total_cost:  8974.427080408483\n",
      "total trades:  1635\n",
      "Sharpe:  0.47856711457833034\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0202901363372803  minutes\n",
      " - A2C Validation from:  20170705 to  20171003\n",
      " - A2C Sharpe Ratio:  0.08079734582553906\n",
      " - Trading from:  20171003 to  20180103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1265908.8893056754\n",
      "end_total_asset:1371773.1241182284\n",
      "total_reward:105864.23481255304\n",
      "total_cost:  5125.436493172875\n",
      "total trades:  1569\n",
      "Sharpe:  0.7386729123615845\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20171003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0405513167381286  minutes\n",
      " - A2C Validation from:  20171003 to  20180103\n",
      " - A2C Sharpe Ratio:  0.17061492580440235\n",
      " - Trading from:  20180103 to  20180405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1371773.1241182284\n",
      "end_total_asset:1398950.3088498367\n",
      "total_reward:27177.184731608257\n",
      "total_cost:  1903.748103441076\n",
      "total trades:  353\n",
      "Sharpe:  0.21406367262058104\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180103\n",
      " - A2C Training\n",
      " - Training time (A2C):  0.9953473885854085  minutes\n",
      " - A2C Validation from:  20180103 to  20180405\n",
      " - A2C Sharpe Ratio:  0.00018070299850850137\n",
      " - Trading from:  20180405 to  20180705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1398950.3088498367\n",
      "end_total_asset:1351951.5666890652\n",
      "total_reward:-46998.74216077151\n",
      "total_cost:  6720.304107298069\n",
      "total trades:  1044\n",
      "Sharpe:  -0.2458459666154328\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180405\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.000807269414266  minutes\n",
      " - A2C Validation from:  20180405 to  20180705\n",
      " - A2C Sharpe Ratio:  0.0021090293351465708\n",
      " - Trading from:  20180705 to  20181003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1351951.5666890652\n",
      "end_total_asset:1363964.1899386207\n",
      "total_reward:12012.623249555472\n",
      "total_cost:  6330.3453500089745\n",
      "total trades:  973\n",
      "Sharpe:  0.171389993007167\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180705\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0077008088429769  minutes\n",
      " - A2C Validation from:  20180705 to  20181003\n",
      " - A2C Sharpe Ratio:  0.11049610669894719\n",
      " - Trading from:  20181003 to  20190104\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1363964.1899386207\n",
      "end_total_asset:1371149.115845297\n",
      "total_reward:7184.925906676333\n",
      "total_cost:  775.9281538609093\n",
      "total trades:  177\n",
      "Sharpe:  0.2604765719081027\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20181003\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0008514682451883  minutes\n",
      " - A2C Validation from:  20181003 to  20190104\n",
      " - A2C Sharpe Ratio:  -0.3254381143367486\n",
      " - Trading from:  20190104 to  20190405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1371149.115845297\n",
      "end_total_asset:1475148.490230917\n",
      "total_reward:103999.37438562\n",
      "total_cost:  4917.987307052535\n",
      "total trades:  1137\n",
      "Sharpe:  0.33174907983413954\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190104\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0150077184041342  minutes\n",
      " - A2C Validation from:  20190104 to  20190405\n",
      " - A2C Sharpe Ratio:  -0.057209608688874924\n",
      " - Trading from:  20190405 to  20190708\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1475148.490230917\n",
      "end_total_asset:1479118.540646858\n",
      "total_reward:3970.0504159410484\n",
      "total_cost:  1167.8856052781891\n",
      "total trades:  170\n",
      "Sharpe:  0.24410722332692364\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190405\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.025445024172465  minutes\n",
      " - A2C Validation from:  20190405 to  20190708\n",
      " - A2C Sharpe Ratio:  0.34529926033178776\n",
      " - Trading from:  20190708 to  20191004\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1479118.540646858\n",
      "end_total_asset:1477195.1129363277\n",
      "total_reward:-1923.4277105303481\n",
      "total_cost:  1768.7877442326162\n",
      "total trades:  314\n",
      "Sharpe:  -0.0523184566795158\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190708\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0312626361846924  minutes\n",
      " - A2C Validation from:  20190708 to  20191004\n",
      " - A2C Sharpe Ratio:  -0.005372002588909421\n",
      " - Trading from:  20191004 to  20200106\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1477195.1129363277\n",
      "end_total_asset:1476201.0379271177\n",
      "total_reward:-994.0750092100352\n",
      "total_cost:  284.7196559606122\n",
      "total trades:  70\n",
      "Sharpe:  -0.32072055744923733\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20191004\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0327062010765076  minutes\n",
      " - A2C Validation from:  20191004 to  20200106\n",
      " - A2C Sharpe Ratio:  -0.41019996584359897\n",
      " - Trading from:  20200106 to  20200406\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1476201.0379271177\n",
      "end_total_asset:1456135.6042760538\n",
      "total_reward:-20065.433651063824\n",
      "total_cost:  971.4451047719512\n",
      "total trades:  154\n",
      "Sharpe:  -0.4112948467572304\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20200106\n",
      " - A2C Training\n",
      " - Training time (A2C):  1.0387340744336446  minutes\n",
      " - A2C Validation from:  20200106 to  20200406\n",
      " - A2C Sharpe Ratio:  -0.3758116630087499\n",
      " - Trading from:  20200406 to  20200707\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1456135.6042760538\n",
      "end_total_asset:1456393.9000445982\n",
      "total_reward:258.2957685443107\n",
      "total_cost:  383.44049011393554\n",
      "total trades:  97\n",
      "Sharpe:  0.03410667836277596\n",
      "A2C Strategy took:  22.388082003593446  minutes\n"
     ]
    }
   ],
   "source": [
    "a2c_sharpe_lst = run_a2c(df=df, unique_trade_date=unique_trade_date, rebalance_window=rebalance_window, validation_window=validation_window)\n",
    "\n",
    "with open('working/a2c_sharpe_list.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerow(a2c_sharpe_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e5b20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sac(df, unique_trade_date, rebalance_window, validation_window):\n",
    "    sac_sharpe_list = []\n",
    "    last_state_sac = []\n",
    "\n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            # inital state\n",
    "            initial = True\n",
    "        else:\n",
    "            # previous state\n",
    "            initial = False\n",
    "\n",
    "        # Tuning trubulence index based on historical data\n",
    "        # Turbulence lookback window is one quarter\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window*30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "            # then we assume that the current market is volatile,\n",
    "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        ## validation env\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \",\n",
    "              unique_trade_date[i - rebalance_window - validation_window])\n",
    "\n",
    "        print(\" - SAC Training\")\n",
    "        model_sac = train_SAC(env_train, model_name=\"SAC_35k_dow_{}\".format(i), timesteps=35000)\n",
    "        print(\" - SAC Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_sac, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_sac = get_validation_sharpe(i)\n",
    "        print(\" - SAC Sharpe Ratio: \", sharpe_sac)\n",
    "\n",
    "        sac_sharpe_list.append(sharpe_sac)\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_sac = DRL_prediction(df=df, model=model_sac, name=\"ensemble\",\n",
    "                                             last_state=last_state_sac, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"SAC Strategy took: \", (end - start) / 60, \" minutes\")\n",
    "\n",
    "    return sac_sharpe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "549baf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20151002\n",
      " - SAC Training\n",
      "WARNING:tensorflow:From c:\\Users\\willr\\miniconda3\\envs\\sb_env\\lib\\site-packages\\stable_baselines\\sac\\policies.py:63: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      " - Training time (SAC):  3.0353273510932923  minutes\n",
      " - SAC Validation from:  20151002 to  20160104\n",
      " - SAC Sharpe Ratio:  0.12585684290867497\n",
      " - Trading from:  20160104 to  20160405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1049022.2351882858\n",
      "total_reward:49022.23518828582\n",
      "total_cost:  1422.4622338568868\n",
      "total trades:  920\n",
      "Sharpe:  0.15089694143755428\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20160104\n",
      " - SAC Training\n",
      " - Training time (SAC):  3.2295806725819904  minutes\n",
      " - SAC Validation from:  20160104 to  20160405\n",
      " - SAC Sharpe Ratio:  0.017675098062660124\n",
      " - Trading from:  20160405 to  20160705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1049022.2351882858\n",
      "end_total_asset:1084690.6270069715\n",
      "total_reward:35668.39181868569\n",
      "total_cost:  172.88903999999997\n",
      "total trades:  1124\n",
      "Sharpe:  0.13221124783962246\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160405\n",
      " - SAC Training\n",
      " - Training time (SAC):  2.940537973244985  minutes\n",
      " - SAC Validation from:  20160405 to  20160705\n",
      " - SAC Sharpe Ratio:  0.12508281592585685\n",
      " - Trading from:  20160705 to  20161003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1084690.6270069715\n",
      "end_total_asset:1086162.880789402\n",
      "total_reward:1472.2537824304309\n",
      "total_cost:  1731.5883589949003\n",
      "total trades:  789\n",
      "Sharpe:  0.013183070594659362\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160705\n",
      " - SAC Training\n",
      " - Training time (SAC):  2.878936795393626  minutes\n",
      " - SAC Validation from:  20160705 to  20161003\n",
      " - SAC Sharpe Ratio:  0.17362655537867275\n",
      " - Trading from:  20161003 to  20170103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1086162.880789402\n",
      "end_total_asset:1095592.6226540767\n",
      "total_reward:9429.741864674725\n",
      "total_cost:  928.9777974647467\n",
      "total trades:  1251\n",
      "Sharpe:  0.05785193616924001\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20161003\n",
      " - SAC Training\n",
      " - Training time (SAC):  31.76826527516047  minutes\n",
      " - SAC Validation from:  20161003 to  20170103\n",
      " - SAC Sharpe Ratio:  0.4955002332148106\n",
      " - Trading from:  20170103 to  20170404\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1095592.6226540767\n",
      "end_total_asset:1135408.124739762\n",
      "total_reward:39815.502085685264\n",
      "total_cost:  1403.228152049205\n",
      "total trades:  754\n",
      "Sharpe:  0.2477623978626458\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20170103\n",
      " - SAC Training\n",
      " - Training time (SAC):  3.2626932422320047  minutes\n",
      " - SAC Validation from:  20170103 to  20170404\n",
      " - SAC Sharpe Ratio:  0.24343679378311484\n",
      " - Trading from:  20170404 to  20170705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1135408.124739762\n",
      "end_total_asset:1140198.3289065242\n",
      "total_reward:4790.204166762298\n",
      "total_cost:  3539.8080085238535\n",
      "total trades:  979\n",
      "Sharpe:  0.034272953530732314\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170404\n",
      " - SAC Training\n",
      " - Training time (SAC):  3.1244523684183756  minutes\n",
      " - SAC Validation from:  20170404 to  20170705\n",
      " - SAC Sharpe Ratio:  0.443666282430212\n",
      " - Trading from:  20170705 to  20171003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1140198.3289065242\n",
      "end_total_asset:1184858.5995934699\n",
      "total_reward:44660.270686945645\n",
      "total_cost:  2466.4143162556256\n",
      "total trades:  1023\n",
      "Sharpe:  0.29575700825090095\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170705\n",
      " - SAC Training\n",
      " - Training time (SAC):  7.3701290885607404  minutes\n",
      " - SAC Validation from:  20170705 to  20171003\n",
      " - SAC Sharpe Ratio:  0.27240261213801487\n",
      " - Trading from:  20171003 to  20180103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1184858.5995934699\n",
      "end_total_asset:1332450.7919734698\n",
      "total_reward:147592.1923799999\n",
      "total_cost:  990.5744000000001\n",
      "total trades:  808\n",
      "Sharpe:  0.6064175458133008\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20171003\n",
      " - SAC Training\n",
      " - Training time (SAC):  4.2760757048924765  minutes\n",
      " - SAC Validation from:  20171003 to  20180103\n",
      " - SAC Sharpe Ratio:  0.4040705521834011\n",
      " - Trading from:  20180103 to  20180405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1332450.7919734698\n",
      "end_total_asset:1339025.0979361583\n",
      "total_reward:6574.305962688522\n",
      "total_cost:  1908.8596159285928\n",
      "total trades:  190\n",
      "Sharpe:  0.03465741289780722\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180103\n",
      " - SAC Training\n",
      " - Training time (SAC):  6.850455367565155  minutes\n",
      " - SAC Validation from:  20180103 to  20180405\n",
      " - SAC Sharpe Ratio:  -0.06021083089058974\n",
      " - Trading from:  20180405 to  20180705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1339025.0979361583\n",
      "end_total_asset:1302205.4268597018\n",
      "total_reward:-36819.67107645655\n",
      "total_cost:  2474.8810334173395\n",
      "total trades:  857\n",
      "Sharpe:  -0.12886797768057642\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180405\n",
      " - SAC Training\n",
      " - Training time (SAC):  3.3036760409673054  minutes\n",
      " - SAC Validation from:  20180405 to  20180705\n",
      " - SAC Sharpe Ratio:  0.13080054297565155\n",
      " - Trading from:  20180705 to  20181003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1302205.4268597018\n",
      "end_total_asset:1330442.2852997014\n",
      "total_reward:28236.858439999633\n",
      "total_cost:  5783.61744\n",
      "total trades:  740\n",
      "Sharpe:  0.22647598699666047\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180705\n",
      " - SAC Training\n",
      " - Training time (SAC):  6.522135579586029  minutes\n",
      " - SAC Validation from:  20180705 to  20181003\n",
      " - SAC Sharpe Ratio:  0.1575530016124405\n",
      " - Trading from:  20181003 to  20190104\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1330442.2852997014\n",
      "end_total_asset:1338508.5592997011\n",
      "total_reward:8066.273999999743\n",
      "total_cost:  736.089\n",
      "total trades:  108\n",
      "Sharpe:  0.23010919425152632\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20181003\n",
      " - SAC Training\n",
      " - Training time (SAC):  7.2389836271603905  minutes\n",
      " - SAC Validation from:  20181003 to  20190104\n",
      " - SAC Sharpe Ratio:  -0.3584809352659421\n",
      " - Trading from:  20190104 to  20190405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1338508.5592997011\n",
      "end_total_asset:1434278.7448284558\n",
      "total_reward:95770.18552875472\n",
      "total_cost:  1471.2095947944792\n",
      "total trades:  1096\n",
      "Sharpe:  0.26365319287547934\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190104\n",
      " - SAC Training\n",
      " - Training time (SAC):  7.362019975980123  minutes\n",
      " - SAC Validation from:  20190104 to  20190405\n",
      " - SAC Sharpe Ratio:  0.1308444959019164\n",
      " - Trading from:  20190405 to  20190708\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1434278.7448284558\n",
      "end_total_asset:1445213.8288284563\n",
      "total_reward:10935.084000000497\n",
      "total_cost:  1507.4279999999992\n",
      "total trades:  112\n",
      "Sharpe:  0.3063520342097559\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190405\n",
      " - SAC Training\n",
      " - Training time (SAC):  7.263125093777974  minutes\n",
      " - SAC Validation from:  20190405 to  20190708\n",
      " - SAC Sharpe Ratio:  0.25091020187925805\n",
      " - Trading from:  20190708 to  20191004\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1445213.8288284563\n",
      "end_total_asset:1440958.096828456\n",
      "total_reward:-4255.732000000309\n",
      "total_cost:  2766.7429999999995\n",
      "total trades:  300\n",
      "Sharpe:  -0.06913766887372971\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190708\n",
      " - SAC Training\n",
      " - Training time (SAC):  6.992309053738912  minutes\n",
      " - SAC Validation from:  20190708 to  20191004\n",
      " - SAC Sharpe Ratio:  -0.11770881972045763\n",
      " - Trading from:  20191004 to  20200106\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1440958.096828456\n",
      "end_total_asset:1438849.4660669703\n",
      "total_reward:-2108.6307614857797\n",
      "total_cost:  355.3860979880525\n",
      "total trades:  64\n",
      "Sharpe:  -0.40343692743156384\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20191004\n",
      " - SAC Training\n",
      " - Training time (SAC):  6.173948299884796  minutes\n",
      " - SAC Validation from:  20191004 to  20200106\n",
      " - SAC Sharpe Ratio:  -0.10476121524240416\n",
      " - Trading from:  20200106 to  20200406\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1438849.4660669703\n",
      "end_total_asset:1402919.6875669698\n",
      "total_reward:-35929.77850000048\n",
      "total_cost:  1783.8365\n",
      "total trades:  200\n",
      "Sharpe:  -0.409089685755754\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20200106\n",
      " - SAC Training\n",
      " - Training time (SAC):  3.4226003766059874  minutes\n",
      " - SAC Validation from:  20200106 to  20200406\n",
      " - SAC Sharpe Ratio:  -0.37910456836870765\n",
      " - Trading from:  20200406 to  20200707\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1402919.6875669698\n",
      "end_total_asset:1409988.0820669697\n",
      "total_reward:7068.394499999937\n",
      "total_cost:  941.5725\n",
      "total trades:  126\n",
      "Sharpe:  0.25466143362046256\n",
      "SAC Strategy took:  117.19932693243027  minutes\n"
     ]
    }
   ],
   "source": [
    "sac_sharpe_lst = run_sac(df=df, unique_trade_date=unique_trade_date, rebalance_window=rebalance_window, validation_window=validation_window)\n",
    "\n",
    "with open('working/sac_sharpe_list.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerow(sac_sharpe_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d4f6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_td3(df, unique_trade_date, rebalance_window, validation_window):\n",
    "    td3_sharpe_list = []\n",
    "    last_state_td3 = []\n",
    "\n",
    "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
    "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
    "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
    "        if i - rebalance_window - validation_window == 0:\n",
    "            # inital state\n",
    "            initial = True\n",
    "        else:\n",
    "            # previous state\n",
    "            initial = False\n",
    "\n",
    "        # Tuning trubulence index based on historical data\n",
    "        # Turbulence lookback window is one quarter\n",
    "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
    "        start_date_index = end_date_index - validation_window*30 + 1\n",
    "\n",
    "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
    "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
    "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
    "\n",
    "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
    "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
    "            # then we assume that the current market is volatile,\n",
    "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
    "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
    "            turbulence_threshold = insample_turbulence_threshold\n",
    "        else:\n",
    "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
    "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
    "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(\" - Turbulence_threshold: \", turbulence_threshold)\n",
    "\n",
    "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
    "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
    "\n",
    "        ## validation env\n",
    "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
    "                                end=unique_trade_date[i - rebalance_window])\n",
    "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
    "                                                          turbulence_threshold=turbulence_threshold,\n",
    "                                                          iteration=i)])\n",
    "        obs_val = env_val.reset()\n",
    "        \n",
    "        print(\" - Model training from: \", 20090000, \"to \",\n",
    "              unique_trade_date[i - rebalance_window - validation_window])\n",
    "\n",
    "        print(\" - TD3 Training\")\n",
    "        model_td3 = train_TD3(env_train, model_name=\"TD3_15k_dow_{}\".format(i), timesteps=15000)\n",
    "        print(\" - TD3 Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
    "              unique_trade_date[i - rebalance_window])\n",
    "        DRL_validation(model=model_td3, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
    "        sharpe_td3 = get_validation_sharpe(i)\n",
    "        print(\" - TD3 Sharpe Ratio: \", sharpe_td3)\n",
    "\n",
    "        td3_sharpe_list.append(sharpe_td3)\n",
    "\n",
    "        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
    "        print(\"-\" * 50)\n",
    "        last_state_td3 = DRL_prediction(df=df, model=model_td3, name=\"ensemble\",\n",
    "                                             last_state=last_state_td3, iter_num=i,\n",
    "                                             unique_trade_date=unique_trade_date,\n",
    "                                             rebalance_window=rebalance_window,\n",
    "                                             turbulence_threshold=turbulence_threshold,\n",
    "                                             initial=initial)\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"TD3 Strategy took: \", (end - start) / 60, \" minutes\")\n",
    "\n",
    "    return td3_sharpe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fca5cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20151002\n",
      " - TD3 Training\n",
      " - Training time (TD3):  0.9650763352711995  minutes\n",
      " - TD3 Validation from:  20151002 to  20160104\n",
      " - TD3 Sharpe Ratio:  0.02797986979048093\n",
      " - Trading from:  20160104 to  20160405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1000000\n",
      "end_total_asset:1061208.1705000002\n",
      "total_reward:61208.17050000024\n",
      "total_cost:  1087.6944999999998\n",
      "total trades:  1184\n",
      "Sharpe:  0.19023434810755638\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20160104\n",
      " - TD3 Training\n",
      " - Training time (TD3):  0.9856189250946045  minutes\n",
      " - TD3 Validation from:  20160104 to  20160405\n",
      " - TD3 Sharpe Ratio:  0.022520188764251183\n",
      " - Trading from:  20160405 to  20160705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1061208.1705000002\n",
      "end_total_asset:1079977.45216\n",
      "total_reward:18769.281659999862\n",
      "total_cost:  1019.01171\n",
      "total trades:  931\n",
      "Sharpe:  0.06823338126461609\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160405\n",
      " - TD3 Training\n",
      " - Training time (TD3):  0.9679521322250366  minutes\n",
      " - TD3 Validation from:  20160405 to  20160705\n",
      " - TD3 Sharpe Ratio:  0.09557827101797332\n",
      " - Trading from:  20160705 to  20161003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1079977.45216\n",
      "end_total_asset:1099291.3046000004\n",
      "total_reward:19313.85244000028\n",
      "total_cost:  767.6948900000001\n",
      "total trades:  851\n",
      "Sharpe:  0.0865471867017079\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20160705\n",
      " - TD3 Training\n",
      " - Training time (TD3):  0.9616781870524088  minutes\n",
      " - TD3 Validation from:  20160705 to  20161003\n",
      " - TD3 Sharpe Ratio:  0.055593194285969934\n",
      " - Trading from:  20161003 to  20170103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1099291.3046000004\n",
      "end_total_asset:1147797.4826300004\n",
      "total_reward:48506.17803000007\n",
      "total_cost:  1648.843690000001\n",
      "total trades:  1109\n",
      "Sharpe:  0.2570269189238647\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20161003\n",
      " - TD3 Training\n",
      " - Training time (TD3):  0.976899528503418  minutes\n",
      " - TD3 Validation from:  20161003 to  20170103\n",
      " - TD3 Sharpe Ratio:  0.39936554564801147\n",
      " - Trading from:  20170103 to  20170404\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1147797.4826300004\n",
      "end_total_asset:1213882.0135500003\n",
      "total_reward:66084.53091999982\n",
      "total_cost:  1024.73283\n",
      "total trades:  746\n",
      "Sharpe:  0.376632523288651\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20170103\n",
      " - TD3 Training\n",
      " - Training time (TD3):  7.32778859535853  minutes\n",
      " - TD3 Validation from:  20170103 to  20170404\n",
      " - TD3 Sharpe Ratio:  0.22609130111096065\n",
      " - Trading from:  20170404 to  20170705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1213882.0135500003\n",
      "end_total_asset:1234514.8819300001\n",
      "total_reward:20632.868379999883\n",
      "total_cost:  3042.388900000001\n",
      "total trades:  982\n",
      "Sharpe:  0.1481850511708888\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170404\n",
      " - TD3 Training\n",
      " - Training time (TD3):  2.2388129234313965  minutes\n",
      " - TD3 Validation from:  20170404 to  20170705\n",
      " - TD3 Sharpe Ratio:  0.2691135193601001\n",
      " - Trading from:  20170705 to  20171003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1234514.8819300001\n",
      "end_total_asset:1300450.8265255913\n",
      "total_reward:65935.94459559117\n",
      "total_cost:  2554.3480574017485\n",
      "total trades:  1188\n",
      "Sharpe:  0.34681297762426716\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20170705\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.132524021466573  minutes\n",
      " - TD3 Validation from:  20170705 to  20171003\n",
      " - TD3 Sharpe Ratio:  0.3941624156887042\n",
      " - Trading from:  20171003 to  20180103\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1300450.8265255913\n",
      "end_total_asset:1437989.7731359906\n",
      "total_reward:137538.9466103993\n",
      "total_cost:  853.0201603894288\n",
      "total trades:  923\n",
      "Sharpe:  0.6117291706057115\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20171003\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.2166072726249695  minutes\n",
      " - TD3 Validation from:  20171003 to  20180103\n",
      " - TD3 Sharpe Ratio:  0.4223247388479016\n",
      " - Trading from:  20180103 to  20180405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1437989.7731359906\n",
      "end_total_asset:1474493.8827693192\n",
      "total_reward:36504.109633328626\n",
      "total_cost:  1331.7344754425444\n",
      "total trades:  152\n",
      "Sharpe:  0.24091890748499212\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180103\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.1299336115519205  minutes\n",
      " - TD3 Validation from:  20180103 to  20180405\n",
      " - TD3 Sharpe Ratio:  -0.03873568575756194\n",
      " - Trading from:  20180405 to  20180705\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1474493.8827693192\n",
      "end_total_asset:1471467.6969474908\n",
      "total_reward:-3026.1858218284324\n",
      "total_cost:  3676.711393554023\n",
      "total trades:  657\n",
      "Sharpe:  -0.004599668535473264\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180405\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.0438101490338643  minutes\n",
      " - TD3 Validation from:  20180405 to  20180705\n",
      " - TD3 Sharpe Ratio:  -0.006519806369522932\n",
      " - Trading from:  20180705 to  20181003\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1471467.6969474908\n",
      "end_total_asset:1499240.0773822323\n",
      "total_reward:27772.3804347415\n",
      "total_cost:  5527.580117944792\n",
      "total trades:  840\n",
      "Sharpe:  0.22327175030307406\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20180705\n",
      " - TD3 Training\n",
      " - Training time (TD3):  0.9394402186075846  minutes\n",
      " - TD3 Validation from:  20180705 to  20181003\n",
      " - TD3 Sharpe Ratio:  0.2772255561357075\n",
      " - Trading from:  20181003 to  20190104\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1499240.0773822323\n",
      "end_total_asset:1525601.830382232\n",
      "total_reward:26361.752999999793\n",
      "total_cost:  1715.712\n",
      "total trades:  189\n",
      "Sharpe:  0.3017242956362314\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  171.09407156310158\n",
      " - Model training from:  20090000 to  20181003\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.1777718782424926  minutes\n",
      " - TD3 Validation from:  20181003 to  20190104\n",
      " - TD3 Sharpe Ratio:  -0.34106779995132563\n",
      " - Trading from:  20190104 to  20190405\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1525601.830382232\n",
      "end_total_asset:1606326.435377936\n",
      "total_reward:80724.60499570402\n",
      "total_cost:  1587.103846360636\n",
      "total trades:  1097\n",
      "Sharpe:  0.21742055385731238\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190104\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.4053983807563781  minutes\n",
      " - TD3 Validation from:  20190104 to  20190405\n",
      " - TD3 Sharpe Ratio:  0.044877581918217\n",
      " - Trading from:  20190405 to  20190708\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1606326.435377936\n",
      "end_total_asset:1612628.4102972285\n",
      "total_reward:6301.974919292377\n",
      "total_cost:  1554.9541371137109\n",
      "total trades:  136\n",
      "Sharpe:  0.23629667905978194\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190405\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.4993409196535745  minutes\n",
      " - TD3 Validation from:  20190405 to  20190708\n",
      " - TD3 Sharpe Ratio:  0.11854664361209051\n",
      " - Trading from:  20190708 to  20191004\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1612628.4102972285\n",
      "end_total_asset:1598586.2687272287\n",
      "total_reward:-14042.141569999745\n",
      "total_cost:  2712.5547500000002\n",
      "total trades:  287\n",
      "Sharpe:  -0.16530854806009276\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20190708\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.4641778469085693  minutes\n",
      " - TD3 Validation from:  20190708 to  20191004\n",
      " - TD3 Sharpe Ratio:  -0.026148708950474997\n",
      " - Trading from:  20191004 to  20200106\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1598586.2687272287\n",
      "end_total_asset:1596968.1547272287\n",
      "total_reward:-1618.1140000000596\n",
      "total_cost:  438.428\n",
      "total trades:  60\n",
      "Sharpe:  -0.45227734666991626\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20191004\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.4942838867505392  minutes\n",
      " - TD3 Validation from:  20191004 to  20200106\n",
      " - TD3 Sharpe Ratio:  -0.3225478851367378\n",
      " - Trading from:  20200106 to  20200406\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1596968.1547272287\n",
      "end_total_asset:1571155.2642272296\n",
      "total_reward:-25812.89049999905\n",
      "total_cost:  1446.6665000000005\n",
      "total trades:  160\n",
      "Sharpe:  -0.34462294049322617\n",
      "--------------------------------------------------\n",
      " - Turbulence_threshold:  96.08032158358223\n",
      " - Model training from:  20090000 to  20200106\n",
      " - TD3 Training\n",
      " - Training time (TD3):  1.5998130321502686  minutes\n",
      " - TD3 Validation from:  20200106 to  20200406\n",
      " - TD3 Sharpe Ratio:  -0.4045905857931531\n",
      " - Trading from:  20200406 to  20200707\n",
      "--------------------------------------------------\n",
      "previous_total_asset:1571155.2642272296\n",
      "end_total_asset:1577075.7447272304\n",
      "total_reward:5920.480500000762\n",
      "total_cost:  836.2094999999999\n",
      "total trades:  98\n",
      "Sharpe:  0.20072782432199593\n",
      "TD3 Strategy took:  28.65327417055766  minutes\n"
     ]
    }
   ],
   "source": [
    "td3_sharpe_lst = run_td3(df=df, unique_trade_date=unique_trade_date, rebalance_window=rebalance_window, validation_window=validation_window)\n",
    "\n",
    "with open('working/sac_sharpe_list.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerow(td3_sharpe_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-sense",
   "metadata": {
    "papermill": {
     "duration": 0.074992,
     "end_time": "2021-04-03T07:46:32.497986",
     "exception": false,
     "start_time": "2021-04-03T07:46:32.422994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 id=\"references\" style=\"color:#eef666; background:#567fb7; border:0.5px dotted;\"> \n",
    "    <center>References\n",
    "        <a class=\"anchor-link\" href=\"#references\" target=\"_self\">¶</a>\n",
    "    </center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-puzzle",
   "metadata": {
    "papermill": {
     "duration": 0.074825,
     "end_time": "2021-04-03T07:46:32.648223",
     "exception": false,
     "start_time": "2021-04-03T07:46:32.573398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hongyang Yang, Xiao-Yang Liu, Shan Zhong, and Anwar Walid. 2020. Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy.<br>\n",
    "In ICAIF ’20: ACM International Conference on AI in Finance, Oct. 15–16, 2020, Manhattan, NY. ACM, New York, NY, USA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10126.704499,
   "end_time": "2021-04-03T07:46:34.243540",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-03T04:57:47.539041",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
